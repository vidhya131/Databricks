{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "870039c2-b0f5-4e45-a511-7479db590b56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## East US (Azure Region)\n",
    "\n",
    "![Image](https://agileit.com/_astro/az-graphic-two.C0qDynBR.png)\n",
    "\n",
    "![Image](https://www.datacenters.com/_next/image?q=75\\&url=https%3A%2F%2Fres.cloudinary.com%2Fhjlz68xhm%2Fimage%2Fupload%2Fmhwxlsnsdld0vqc4nc4p\\&w=384)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/route-server/media/multiregion/multiregion.png)\n",
    "\n",
    "![Image](https://sparxsystems.com/resources/gallery/diagrams/images/multi-region-web-app.png)\n",
    "\n",
    "**East US has 3 Availability Zones (AZs).**\n",
    "\n",
    "### What that means:\n",
    "\n",
    "* ‚úÖ **3 physically separate datacenter locations**\n",
    "* ‚úÖ Independent power, cooling, and networking\n",
    "* ‚úÖ Low-latency connection between zones (typically < 2 ms)\n",
    "* ‚úÖ Designed for high availability and zone-redundant deployments\n",
    "\n",
    "You can deploy:\n",
    "\n",
    "* Zone-redundant services (like ZRS storage)\n",
    "* Zone-pinned VMs\n",
    "* Multi-AZ architectures for 99.99%+ uptime designs\n",
    "\n",
    "If you want, tell me what service you're planning (VM, AKS, SQL, etc.) and I‚Äôll explain how AZ works for that specifically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d57a35c7-cc01-4d5f-91fa-ecec80f9c5ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Why Availability Zones (AZs) are needed in East US\n",
    "\n",
    "![Image](https://agileit.com/_astro/az-graphic-two.C0qDynBR.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/architecture/high-availability/images/high-availability-multi-region-web-v-10.png)\n",
    "\n",
    "![Image](https://ih1.dpstele.com/images/power-outage.webp)\n",
    "\n",
    "![Image](https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4fn80cCKCVWYn0XOOh3eX2/e23f4144cdb106dc80bd3b8a27f27254/image3-11.png)\n",
    "\n",
    "Availability Zones exist for **high availability and fault tolerance**.\n",
    "\n",
    "A single data center can fail. An AZ design protects you from that.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß What problem do AZs solve?\n",
    "\n",
    "### 1Ô∏è‚É£ Data center failures happen\n",
    "\n",
    "Even hyperscale facilities can experience:\n",
    "\n",
    "* Power outages\n",
    "* Cooling failures\n",
    "* Network outages\n",
    "* Hardware failures\n",
    "* Natural disasters\n",
    "\n",
    "If everything runs in one building ‚Üí your app goes down.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ AZs isolate failure domains\n",
    "\n",
    "Each Availability Zone:\n",
    "\n",
    "* Is a **separate physical location**\n",
    "* Has independent **power, cooling, networking**\n",
    "* Is connected with **low-latency private fiber**\n",
    "\n",
    "If Zone 1 fails ‚Üí Zones 2 and 3 keep running.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Enables High Availability Architectures\n",
    "\n",
    "With 3 AZs in East US, you can:\n",
    "\n",
    "* Run VMs in multiple zones\n",
    "* Use zone-redundant storage (ZRS)\n",
    "* Deploy AKS node pools across zones\n",
    "* Use load balancers across zones\n",
    "\n",
    "This helps achieve:\n",
    "\n",
    "* 99.99%+ uptime\n",
    "* Better SLA guarantees\n",
    "* Resilience for production systems\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Simple analogy\n",
    "\n",
    "Think of AZs like:\n",
    "\n",
    "* Not storing all your money in one bank branch\n",
    "* Not hosting your entire company in one building\n",
    "\n",
    "If one location burns down, you don‚Äôt lose everything.\n",
    "\n",
    "---\n",
    "\n",
    "## When do you really need AZ?\n",
    "\n",
    "AZ is critical for:\n",
    "\n",
    "* Production workloads\n",
    "* Customer-facing apps\n",
    "* Financial systems\n",
    "* Healthcare systems\n",
    "* E-commerce platforms\n",
    "\n",
    "For dev/test environments?\n",
    "Usually not necessary.\n",
    "\n",
    "---\n",
    "\n",
    "If you'd like, tell me what you're building and I‚Äôll tell you whether you *actually* need multi-AZ or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae4191da-7f2d-49a6-a1eb-c39556bfa2c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is one of the most confusing topics in Databricks ‚Äî let‚Äôs make it very clear üëå\n",
    "\n",
    "---\n",
    "\n",
    "# üèû 1Ô∏è‚É£ Data Lake\n",
    "\n",
    "![Image](https://miro.medium.com/1%2AHp24J2YlyW6oe9skN6gVYw.png)\n",
    "\n",
    "![Image](https://www.altexsoft.com/static/blog-post/2024/4/984d355c-0793-4051-9c61-d8237412fdc6.jpg)\n",
    "\n",
    "![Image](https://images.prismic.io/encord/ZgWeSMt2UUcvBQo1_image3.png?auto=format%2Ccompress)\n",
    "\n",
    "![Image](https://azure.github.io/Storage/docs/analytics/hitchhikers-guide-to-the-datalake/images/data_lake_zones.png)\n",
    "\n",
    "A **Data Lake** is just **storage**.\n",
    "\n",
    "It stores:\n",
    "\n",
    "* CSV files\n",
    "* JSON files\n",
    "* Parquet files\n",
    "* Images\n",
    "* Logs\n",
    "* Raw data\n",
    "\n",
    "In Azure, this is usually:\n",
    "\n",
    "* Microsoft Azure Data Lake Storage Gen2 (ADLS)\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "> üóÑ A giant cloud folder system.\n",
    "\n",
    "‚ö† No schema enforcement\n",
    "‚ö† No ACID transactions\n",
    "‚ö† No built-in versioning\n",
    "\n",
    "Just files.\n",
    "\n",
    "---\n",
    "\n",
    "# üåä 2Ô∏è‚É£ Delta Lake\n",
    "\n",
    "![Image](https://assets.qlik.com/image/upload/w_1408/q_auto/qlik/glossary/data-lake/seo-hero-delta-lake_n8zbs4.jpg)\n",
    "\n",
    "![Image](https://www.databricks.com/sites/default/files/2025-04/diving-into-delta-lake-unpacking-the-transaction-log-2x.png)\n",
    "\n",
    "![Image](https://av-eks-blogoptimized.s3.amazonaws.com/50982Delta%20lake%202.png)\n",
    "\n",
    "![Image](https://miro.medium.com/0%2A2EMqcFu0OaDK4DfB.png)\n",
    "\n",
    "Delta Lake is a **storage layer** built on top of a data lake.\n",
    "\n",
    "It adds:\n",
    "\n",
    "* ‚úÖ ACID transactions\n",
    "* ‚úÖ Schema enforcement\n",
    "* ‚úÖ Time travel (version history)\n",
    "* ‚úÖ Upserts & deletes (MERGE)\n",
    "* ‚úÖ Transaction log (`_delta_log` folder)\n",
    "\n",
    "It turns a messy data lake into a **reliable data system**.\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "> üß† Smart layer added on top of storage.\n",
    "\n",
    "Still stored as files ‚Äî but now with rules and tracking.\n",
    "\n",
    "---\n",
    "\n",
    "# üßæ 3Ô∏è‚É£ Delta Table\n",
    "\n",
    "A **Delta Table** is simply:\n",
    "\n",
    "> A table stored in Delta Lake format.\n",
    "\n",
    "So:\n",
    "\n",
    "* Data Lake ‚Üí storage\n",
    "* Delta Lake ‚Üí rules + transaction layer\n",
    "* Delta Table ‚Üí actual dataset using Delta format\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "/mnt/datalake/sales/\n",
    "    part-000.parquet\n",
    "    part-001.parquet\n",
    "    _delta_log/\n",
    "```\n",
    "\n",
    "That folder = one Delta table.\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Simple Comparison\n",
    "\n",
    "| Concept     | What It Is                 | Analogy            |\n",
    "| ----------- | -------------------------- | ------------------ |\n",
    "| Data Lake   | Storage system             | Hard drive         |\n",
    "| Delta Lake  | Smart storage framework    | Database engine    |\n",
    "| Delta Table | A table using Delta format | One database table |\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Real-World Flow in Databricks\n",
    "\n",
    "1. Raw files land in ADLS (Data Lake)\n",
    "2. Convert to Delta format ‚Üí becomes Delta Lake managed\n",
    "3. Query as Delta Tables in Databricks\n",
    "\n",
    "---\n",
    "\n",
    "# üí° One-Sentence Summary\n",
    "\n",
    "All Delta tables live inside a data lake,\n",
    "but not all data lake files are Delta tables.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can next explain:\n",
    "\n",
    "* Delta vs traditional SQL database\n",
    "* Or when NOT to use Delta Lake üëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e550b176-7270-4bdd-bd8c-7c8e51465739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üöÄ Horizontal Scaling vs Vertical Scaling\n",
    "\n",
    "![Image](https://miro.medium.com/1%2Agee5Zkih2dZ7tYWRgmRbkw.png)\n",
    "\n",
    "![Image](https://media.licdn.com/dms/image/v2/C4E12AQGv6K8fizlDDQ/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1564486772801?e=2147483647\\&t=C9DfS-6gMvWguXhm4QUjGjIHde5cjytqk7dZ-cA88mU\\&v=beta)\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/autoscaling/ec2/userguide/images/elb-tutorial-architecture-diagram.png)\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/autoscaling/ec2/userguide/images/sample-3-tier-architecture-auto-scaling-diagram.png)\n",
    "\n",
    "These are two different ways to handle increasing load in systems like databases, web apps, or Spark clusters.\n",
    "\n",
    "---\n",
    "\n",
    "# üîº Vertical Scaling (Scale Up)\n",
    "\n",
    "**Add more power to one machine.**\n",
    "\n",
    "Example:\n",
    "\n",
    "* Increase CPU from 4 cores ‚Üí 16 cores\n",
    "* Increase RAM from 16GB ‚Üí 128GB\n",
    "* Move to a larger VM size\n",
    "\n",
    "### ‚úÖ Advantages\n",
    "\n",
    "* Simple to implement\n",
    "* No architecture changes\n",
    "* Good for monolithic apps\n",
    "\n",
    "### ‚ùå Disadvantages\n",
    "\n",
    "* Has hardware limits\n",
    "* Can be expensive\n",
    "* Single point of failure\n",
    "* Requires downtime in many cases\n",
    "\n",
    "### üß† Analogy\n",
    "\n",
    "Instead of hiring more workers, you make one worker stronger.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚û° Horizontal Scaling (Scale Out)\n",
    "\n",
    "**Add more machines.**\n",
    "\n",
    "Example:\n",
    "\n",
    "* 1 server ‚Üí 10 servers\n",
    "* 2 Spark workers ‚Üí 20 workers\n",
    "* Load balancer distributes traffic\n",
    "\n",
    "### ‚úÖ Advantages\n",
    "\n",
    "* High availability\n",
    "* No single point of failure\n",
    "* Nearly unlimited scaling\n",
    "* Cloud-native approach\n",
    "\n",
    "### ‚ùå Disadvantages\n",
    "\n",
    "* More complex architecture\n",
    "* Requires distributed system design\n",
    "\n",
    "### üß† Analogy\n",
    "\n",
    "Instead of one super worker, hire more workers.\n",
    "\n",
    "---\n",
    "\n",
    "# üí° In Cloud & Databricks Context\n",
    "\n",
    "In Databricks:\n",
    "\n",
    "* Increasing cluster node size = **Vertical scaling**\n",
    "* Adding more worker nodes = **Horizontal scaling**\n",
    "\n",
    "Most big data systems (Spark, Kafka, distributed DBs) are built for **horizontal scaling**.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Quick Comparison\n",
    "\n",
    "| Feature           | Vertical | Horizontal |\n",
    "| ----------------- | -------- | ---------- |\n",
    "| Add CPU/RAM       | ‚úÖ        | ‚ùå          |\n",
    "| Add More Machines | ‚ùå        | ‚úÖ          |\n",
    "| High Availability | ‚ùå        | ‚úÖ          |\n",
    "| Complexity        | Low      | Higher     |\n",
    "| Cloud-native      | Limited  | Ideal      |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ When to Use What?\n",
    "\n",
    "* Small app? ‚Üí Vertical scaling is fine\n",
    "* Big data, high traffic, enterprise systems? ‚Üí Horizontal scaling\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can explain how this applies specifically to:\n",
    "\n",
    "* Databases\n",
    "* Databricks clusters\n",
    "* Kubernetes\n",
    "* Or system design interviews üëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f9e4de4-97e0-42ac-9a0c-32cb188861e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚ö° Spot Instances (Cloud Cost Optimization)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/10/02/appnext-arch-final-drawing.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/architecture/guide/spot/media/spot-virtual-machine-architecture.svg)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/02/24/interruption_notices_arch_diagram.jpg)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2025/11/02/bdb-5236-architecture.png)\n",
    "\n",
    "**Spot instances** are **discounted cloud virtual machines** that use spare capacity from the cloud provider.\n",
    "\n",
    "You can get:\n",
    "\n",
    "* üí∞ 50‚Äì90% cheaper than regular VMs\n",
    "  But‚Ä¶\n",
    "* ‚ö† They can be taken away at any time.\n",
    "\n",
    "---\n",
    "\n",
    "# üè¢ Examples\n",
    "\n",
    "* Amazon EC2 Spot Instances\n",
    "* Microsoft Azure Spot Virtual Machines\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Why Are They Cheap?\n",
    "\n",
    "Cloud providers have unused servers.\n",
    "\n",
    "Instead of leaving them idle:\n",
    "\n",
    "* They sell them at a big discount.\n",
    "* If capacity is needed, your VM is terminated.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚õî The Catch\n",
    "\n",
    "Spot instances:\n",
    "\n",
    "* Can be evicted with short notice (30 seconds‚Äì2 minutes)\n",
    "* No uptime guarantee\n",
    "* Not ideal for critical production workloads\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ When To Use Spot\n",
    "\n",
    "Great for:\n",
    "\n",
    "* Batch jobs\n",
    "* Data processing\n",
    "* Spark workers\n",
    "* CI/CD pipelines\n",
    "* ML training\n",
    "* Dev/test environments\n",
    "\n",
    "Not good for:\n",
    "\n",
    "* Production databases\n",
    "* Stateful systems\n",
    "* Customer-facing APIs\n",
    "\n",
    "---\n",
    "\n",
    "# ‚öô In Databricks Context\n",
    "\n",
    "In Databricks:\n",
    "\n",
    "* Driver node ‚Üí usually on-demand (stable)\n",
    "* Worker nodes ‚Üí can use spot instances\n",
    "\n",
    "If a worker is killed:\n",
    "\n",
    "* Spark redistributes work\n",
    "* Cluster auto-recovers\n",
    "\n",
    "This makes spot perfect for big data workloads.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Quick Comparison\n",
    "\n",
    "| Feature            | On-Demand VM | Spot VM         |\n",
    "| ------------------ | ------------ | --------------- |\n",
    "| Price              | High         | Very Low        |\n",
    "| Guaranteed uptime  | Yes          | No              |\n",
    "| Can be interrupted | No           | Yes             |\n",
    "| Best for           | Production   | Batch workloads |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Simple Analogy\n",
    "\n",
    "Spot instance = Discount airline ticket\n",
    "Cheap, but your flight might get canceled.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can explain:\n",
    "\n",
    "* Spot vs Reserved instances\n",
    "* How eviction works technically\n",
    "* Or how to safely use spot in Databricks üëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c26d6e63-b335-45b2-86c8-fd38e6383a9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Short answer: **Technically yes in some systems ‚Äî but almost always a bad idea.**\n",
    "\n",
    "Let‚Äôs break it down clearly.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† What Is a Master (Driver) Node?\n",
    "\n",
    "In distributed systems (like Spark, Hadoop, Kubernetes):\n",
    "\n",
    "* **Master / Driver node** = controls the cluster\n",
    "* Schedules work\n",
    "* Tracks state\n",
    "* Manages workers\n",
    "\n",
    "If it dies ‚Üí the whole job usually fails.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ö† Why Spot Is Risky for Master Node\n",
    "\n",
    "Remember:\n",
    "\n",
    "Spot instances:\n",
    "\n",
    "* Can be terminated anytime\n",
    "* Have no uptime guarantee\n",
    "\n",
    "If your **master node** is spot:\n",
    "\n",
    "* ‚ùå Cluster goes down if evicted\n",
    "* ‚ùå Running jobs fail\n",
    "* ‚ùå State may be lost\n",
    "* ‚ùå Production pipelines break\n",
    "\n",
    "That‚Äôs why it‚Äôs usually avoided.\n",
    "\n",
    "---\n",
    "\n",
    "# üî• In Databricks\n",
    "\n",
    "Best practice:\n",
    "\n",
    "* ‚úÖ Driver node ‚Üí On-demand (stable VM)\n",
    "* ‚úÖ Worker nodes ‚Üí Spot (cheap & replaceable)\n",
    "\n",
    "If a worker dies:\n",
    "\n",
    "* Spark recomputes lost tasks\n",
    "* Cluster recovers automatically\n",
    "\n",
    "If driver dies:\n",
    "\n",
    "* Entire job fails\n",
    "\n",
    "So driver = stable\n",
    "Workers = disposable\n",
    "\n",
    "---\n",
    "\n",
    "# üèó When Could Master Be Spot?\n",
    "\n",
    "Only when:\n",
    "\n",
    "* It‚Äôs a short-lived batch cluster\n",
    "* Job is retry-safe\n",
    "* No long-running service\n",
    "* Cost is more important than reliability\n",
    "\n",
    "Even then, it's risky.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Quick Rule\n",
    "\n",
    "| Node Type       | Spot Safe?    |\n",
    "| --------------- | ------------- |\n",
    "| Worker          | ‚úÖ Yes         |\n",
    "| Master / Driver | üö´ Usually No |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Simple Analogy\n",
    "\n",
    "Workers = temporary contractors\n",
    "Master = project manager\n",
    "\n",
    "You can replace contractors easily.\n",
    "Losing the manager mid-project? Chaos.\n",
    "\n",
    "---\n",
    "\n",
    "If you'd like, I can explain:\n",
    "\n",
    "* How auto-recovery works in Spark\n",
    "* Or how production clusters are designed in enterprise setups üëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e820083-f31c-46fb-9644-ee477bfdc38b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In cloud platforms like **Amazon Web Services**, **Microsoft Azure**, and **Google Cloud**, **tags** are key-value labels you attach to resources (VMs, storage, databases, etc.) to organize, track, and manage them.\n",
    "\n",
    "---\n",
    "\n",
    "# üîñ What Is a Tag?\n",
    "\n",
    "A **tag = Key + Value**\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Environment = Production\n",
    "Owner = DataTeam\n",
    "Project = CustomerAnalytics\n",
    "CostCenter = FIN-001\n",
    "```\n",
    "\n",
    "Think of tags like sticky notes attached to your cloud resources.\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Why Tags Are Useful\n",
    "\n",
    "## 1Ô∏è‚É£ Cost Tracking (Very Important üí∞)\n",
    "\n",
    "Imagine your company has 3 teams:\n",
    "\n",
    "* Data Team\n",
    "* Dev Team\n",
    "* ML Team\n",
    "\n",
    "All of them create resources like:\n",
    "\n",
    "* Virtual Machines\n",
    "* Databases\n",
    "* Storage\n",
    "\n",
    "Without tags ‚Üí You get one big cloud bill üòµ\n",
    "With tags ‚Üí You can split the bill by team.\n",
    "\n",
    "Example:\n",
    "\n",
    "| Resource | Monthly Cost | Tag       |\n",
    "| -------- | ------------ | --------- |\n",
    "| VM-01    | $500         | Team=Data |\n",
    "| VM-02    | $300         | Team=Dev  |\n",
    "| DB-01    | $700         | Team=Data |\n",
    "\n",
    "Now you can filter costs by:\n",
    "\n",
    "```\n",
    "Team = Data\n",
    "```\n",
    "\n",
    "And see exactly how much the Data team spends.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Environment Separation (Dev / Test / Prod)\n",
    "\n",
    "Companies usually have:\n",
    "\n",
    "* Dev\n",
    "* Test\n",
    "* Production\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Environment = Dev\n",
    "Environment = Prod\n",
    "```\n",
    "\n",
    "Now:\n",
    "\n",
    "* You can delete all **Dev** resources safely.\n",
    "* You avoid accidentally shutting down Production.\n",
    "\n",
    "Very common real-world use case.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Access Control (Security)\n",
    "\n",
    "You can use tags to control who can manage resources.\n",
    "\n",
    "Example in Azure:\n",
    "\n",
    "```\n",
    "Owner = Harish\n",
    "```\n",
    "\n",
    "Then create a rule:\n",
    "\n",
    "* Only Harish can modify resources with `Owner=Harish`.\n",
    "\n",
    "This is used in:\n",
    "\n",
    "* IAM policies in AWS\n",
    "* Azure RBAC conditions\n",
    "* GCP IAM conditions\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Automation\n",
    "\n",
    "You can automate actions using tags.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "AutoShutdown = Yes\n",
    "```\n",
    "\n",
    "A script runs every night:\n",
    "\n",
    "* Finds resources with `AutoShutdown=Yes`\n",
    "* Stops them at 10 PM\n",
    "\n",
    "This saves money üí∏\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Governance & Compliance\n",
    "\n",
    "For example, your company policy says:\n",
    "\n",
    "Every resource MUST have:\n",
    "\n",
    "* Environment\n",
    "* Owner\n",
    "* CostCenter\n",
    "\n",
    "If someone creates a VM without tags ‚Üí creation is blocked.\n",
    "\n",
    "This helps in:\n",
    "\n",
    "* Large enterprises\n",
    "* Fintech companies\n",
    "* Regulated industries\n",
    "\n",
    "---\n",
    "\n",
    "# üè¢ Real Company Example\n",
    "\n",
    "Let‚Äôs say your company uses **Microsoft Azure** and runs:\n",
    "\n",
    "* 50 VMs\n",
    "* 20 Databases\n",
    "* 10 Storage Accounts\n",
    "\n",
    "You apply this tagging strategy:\n",
    "\n",
    "| Key         | Example Values      |\n",
    "| ----------- | ------------------- |\n",
    "| Environment | Dev / Test / Prod   |\n",
    "| Team        | Data / ML / Backend |\n",
    "| Owner       | Person name         |\n",
    "| Project     | CustomerApp         |\n",
    "| CostCenter  | FIN-001             |\n",
    "\n",
    "Now finance can:\n",
    "\n",
    "* Filter cost by Project\n",
    "* Audit unused resources\n",
    "* Charge back teams\n",
    "\n",
    "Without tags ‚Üí chaos\n",
    "With tags ‚Üí full control\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Simple Analogy\n",
    "\n",
    "Think of tags like:\n",
    "\n",
    "* Labels on folders in a cabinet\n",
    "* Hashtags on Instagram\n",
    "* Categories in Gmail\n",
    "\n",
    "They don‚Äôt change the resource itself ‚Äî\n",
    "They just help you organize and control it.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ö° Interview-Level Summary\n",
    "\n",
    "Tags in cloud are used for:\n",
    "\n",
    "* Cost allocation\n",
    "* Resource organization\n",
    "* Access control\n",
    "* Automation\n",
    "* Governance\n",
    "* Compliance\n",
    "* Billing reports\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also explain:\n",
    "\n",
    "* Tag strategy best practices (enterprise level)\n",
    "* Difference between tags and labels\n",
    "* Real Azure/AWS tagging limits\n",
    "* How Databricks uses tags internally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb94811a-5813-439b-a462-a542d88ea0c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Question: What is policy while creating DBX cluster in Azure Databricks?**\n",
    "\n",
    "---\n",
    "\n",
    "### **Answer:**\n",
    "\n",
    "A **Cluster Policy** in **Azure Databricks** is a **set of rules that control how clusters can be created**.\n",
    "\n",
    "It restricts:\n",
    "\n",
    "* VM size\n",
    "* Number of nodes\n",
    "* Auto-scaling limits\n",
    "* Spot instance usage\n",
    "* Runtime version\n",
    "* And other cluster settings\n",
    "\n",
    "üëâ In simple words:\n",
    "**Policy = Governance rules for cluster creation**\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Why Cluster Policies Are Needed\n",
    "\n",
    "In companies:\n",
    "\n",
    "* Many users create clusters.\n",
    "* Without control ‚Üí people create very large clusters.\n",
    "* This increases cloud cost üí∏\n",
    "* Can also violate security rules.\n",
    "\n",
    "So admins create **cluster policies** to:\n",
    "\n",
    "* Control cost\n",
    "* Enforce standards\n",
    "* Prevent misuse\n",
    "* Maintain governance\n",
    "\n",
    "---\n",
    "\n",
    "# üè¢ Example Scenario\n",
    "\n",
    "Let‚Äôs say your company uses **Microsoft Azure**.\n",
    "\n",
    "Admin creates a policy:\n",
    "\n",
    "```\n",
    "Max Workers = 5\n",
    "VM Size = Standard_DS3_v2 only\n",
    "Auto Termination = 30 minutes\n",
    "Spot Instances = Not Allowed\n",
    "```\n",
    "\n",
    "Now when a developer tries to:\n",
    "\n",
    "* Create 20 workers ‚ùå (blocked)\n",
    "* Choose large VM ‚ùå (not allowed)\n",
    "* Disable auto-termination ‚ùå (not allowed)\n",
    "\n",
    "They must follow the policy.\n",
    "\n",
    "---\n",
    "\n",
    "# üîê Types of Restrictions in Cluster Policy\n",
    "\n",
    "Cluster policies can:\n",
    "\n",
    "### 1Ô∏è‚É£ Fix a value (User cannot change)\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Auto Termination = 30 mins (fixed)\n",
    "```\n",
    "\n",
    "### 2Ô∏è‚É£ Limit a range\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Min Workers = 1\n",
    "Max Workers = 5\n",
    "```\n",
    "\n",
    "### 3Ô∏è‚É£ Hide settings\n",
    "\n",
    "User won‚Äôt even see certain advanced options.\n",
    "\n",
    "---\n",
    "\n",
    "# üí∞ Cost Control Example\n",
    "\n",
    "Without policy:\n",
    "\n",
    "* User creates 10 clusters\n",
    "* Each with 16 workers\n",
    "* No auto-termination\n",
    "\n",
    "Huge Azure bill üòµ\n",
    "\n",
    "With policy:\n",
    "\n",
    "* Max 5 workers\n",
    "* Auto-terminate after 30 mins\n",
    "* Only approved VM types\n",
    "\n",
    "Cost stays controlled.\n",
    "\n",
    "---\n",
    "\n",
    "# üèõ Enterprise-Level Importance\n",
    "\n",
    "Cluster Policies help in:\n",
    "\n",
    "* Data governance\n",
    "* Budget control\n",
    "* Security compliance\n",
    "* Standardization across teams\n",
    "\n",
    "Large companies always use cluster policies.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Simple Analogy\n",
    "\n",
    "Think of Cluster Policy like:\n",
    "\n",
    "* Company laptop purchase rules\n",
    "* Only certain models allowed\n",
    "* Budget limit fixed\n",
    "\n",
    "You can buy ‚Äî\n",
    "But within company rules.\n",
    "\n",
    "---\n",
    "\n",
    "# üìù Interview-Ready Definition\n",
    "\n",
    "> A Cluster Policy in Azure Databricks is a governance mechanism that defines rules and restrictions for cluster configuration to control cost, enforce standards, and maintain security compliance.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* Difference between Cluster Policy and RBAC\n",
    "* How policies are written (JSON format)\n",
    "* What happens if no policy is used in enterprise setups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dabaa4af-20f6-4b07-b560-ddf48c2e07e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **What is the purpose of a cluster pool?**\n",
    "\n",
    "The **purpose of a cluster pool** (in Databricks) is to **reduce cluster startup time and lower infrastructure costs** by keeping a set of pre-started virtual machines (VMs) ready to use.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ What is a Cluster Pool?\n",
    "\n",
    "A **cluster pool** is a group of **pre-created, idle virtual machines** that are ready to be attached to a cluster immediately.\n",
    "\n",
    "Instead of:\n",
    "\n",
    "* Creating new VMs every time you start a cluster ‚ùå\n",
    "\n",
    "It:\n",
    "\n",
    "* Reuses already running VMs from the pool ‚úÖ\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Why is it Needed?\n",
    "\n",
    "### 1Ô∏è‚É£ Faster Cluster Startup\n",
    "\n",
    "Without a pool:\n",
    "\n",
    "* Databricks requests new VMs from Azure/AWS\n",
    "* VM provisioning takes **2‚Äì5 minutes**\n",
    "\n",
    "With a pool:\n",
    "\n",
    "* VMs are already running\n",
    "* Cluster starts in **10‚Äì20 seconds**\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Cost Optimization\n",
    "\n",
    "* Idle VMs in the pool can be auto-terminated after a timeout.\n",
    "* Reduces cloud provisioning overhead.\n",
    "* Helps teams avoid repeatedly creating/destroying infrastructure.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Better Resource Management\n",
    "\n",
    "* Admins control:\n",
    "\n",
    "  * VM type\n",
    "  * Min & max pool size\n",
    "  * Auto-termination settings\n",
    "* Ensures consistent compute for teams.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Simple Example\n",
    "\n",
    "Imagine a company using Databricks in Azure:\n",
    "\n",
    "* Data engineers run jobs throughout the day.\n",
    "* They create clusters multiple times.\n",
    "\n",
    "Without Pool:\n",
    "\n",
    "* Every job waits 3‚Äì4 minutes for cluster startup.\n",
    "\n",
    "With Pool:\n",
    "\n",
    "* Company keeps 5 VMs warm in a pool.\n",
    "* Jobs start almost instantly.\n",
    "* Developers are more productive.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Real-Life Analogy\n",
    "\n",
    "Cluster pool = **Parking lot with cars already running üöó**\n",
    "\n",
    "Instead of building a new car every time you want to drive,\n",
    "you just pick one that‚Äôs already ready.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ When Should You Use It?\n",
    "\n",
    "Use cluster pools when:\n",
    "\n",
    "* Many short-lived clusters are created\n",
    "* Teams frequently start/stop clusters\n",
    "* You want faster startup time\n",
    "* You want cost control\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also explain:\n",
    "\n",
    "* Difference between **cluster pool vs job cluster**\n",
    "* How cluster pool works in **Azure Databricks**\n",
    "* When NOT to use cluster pools**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aafebd5b-deb0-4ea1-904e-126a7357d8d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **What is a Cluster Policy in Databricks (DBX)?**\n",
    "\n",
    "**Cluster policy in Databricks (DBX)** is a set of rules that **controls how clusters can be created and configured** inside a Databricks workspace.\n",
    "\n",
    "It helps organizations:\n",
    "\n",
    "* Control costs üí∞\n",
    "* Enforce security üîê\n",
    "* Standardize configurations ‚öôÔ∏è\n",
    "* Prevent misuse of resources\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Why Do We Need Cluster Policy?\n",
    "\n",
    "Without cluster policies:\n",
    "\n",
    "* Users can create very large clusters\n",
    "* Users can select expensive VM types\n",
    "* Users can enable risky configurations\n",
    "* Costs can go out of control\n",
    "\n",
    "Cluster policies act like **guardrails**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß± How It Works\n",
    "\n",
    "A cluster policy:\n",
    "\n",
    "* Defines allowed VM types\n",
    "* Sets min/max number of workers\n",
    "* Forces certain settings (like auto-termination)\n",
    "* Restricts use of spot instances\n",
    "* Controls runtime versions\n",
    "\n",
    "When a user creates a cluster, they:\n",
    "\n",
    "* Must follow the policy\n",
    "* Cannot change restricted fields\n",
    "\n",
    "---\n",
    "\n",
    "## üè¢ Real-World Example\n",
    "\n",
    "Imagine a company using **Databricks**.\n",
    "\n",
    "### Without Policy:\n",
    "\n",
    "A developer creates:\n",
    "\n",
    "* 20 worker nodes\n",
    "* Large VM size\n",
    "* No auto-termination\n",
    "* Runs all weekend\n",
    "\n",
    "üëâ Huge cloud bill.\n",
    "\n",
    "### With Policy:\n",
    "\n",
    "Company creates a policy:\n",
    "\n",
    "* Max 5 workers\n",
    "* Only Standard_DS3_v2 VM allowed\n",
    "* Auto-terminate after 60 minutes\n",
    "* Spot instances only\n",
    "\n",
    "Now:\n",
    "\n",
    "* No one can exceed limits\n",
    "* Cost is controlled\n",
    "* Environment stays secure\n",
    "\n",
    "---\n",
    "\n",
    "## üõ† Example Cluster Policy (Simple JSON)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"num_workers\": {\n",
    "    \"type\": \"range\",\n",
    "    \"minValue\": 1,\n",
    "    \"maxValue\": 5\n",
    "  },\n",
    "  \"node_type_id\": {\n",
    "    \"type\": \"fixed\",\n",
    "    \"value\": \"Standard_DS3_v2\"\n",
    "  },\n",
    "  \"autotermination_minutes\": {\n",
    "    \"type\": \"fixed\",\n",
    "    \"value\": 60\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This means:\n",
    "\n",
    "* Workers: 1‚Äì5 only\n",
    "* VM size: fixed\n",
    "* Auto-terminate: 60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## üîê Who Creates Cluster Policies?\n",
    "\n",
    "* Workspace Admins\n",
    "* Platform / Cloud team\n",
    "\n",
    "Regular users:\n",
    "\n",
    "* Can only select from available policies\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Types of Restrictions in Policy\n",
    "\n",
    "| Type      | Meaning                      |\n",
    "| --------- | ---------------------------- |\n",
    "| fixed     | User cannot change it        |\n",
    "| range     | User can choose within limit |\n",
    "| allowlist | Only specific values allowed |\n",
    "| forbidden | Setting not allowed          |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† In Simple Words\n",
    "\n",
    "Cluster policy in DBX =\n",
    "üëâ **Rules that control how clusters are created to manage cost, security, and performance.**\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also explain:\n",
    "\n",
    "* Cluster policy vs Azure Policy\n",
    "* How to create cluster policy step-by-step\n",
    "* Interview explanation version üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8691efe5-f510-4611-b118-e92d7cfddd18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **What is equivalent to Cluster Policy in AWS?**\n",
    "\n",
    "The **equivalent to Cluster Policy in AWS** is mainly:\n",
    "\n",
    "> **IAM Policies + Service Control Policies (SCP) + Service-specific restrictions**\n",
    "\n",
    "There is no single feature in AWS exactly called ‚ÄúCluster Policy‚Äù like in **Databricks**, but AWS achieves similar control using multiple services.\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ 1Ô∏è‚É£ IAM Policy (Main Equivalent)\n",
    "\n",
    "The closest equivalent is:\n",
    "\n",
    "## üëâ **AWS Identity and Access Management (IAM Policy)**\n",
    "\n",
    "IAM policies control:\n",
    "\n",
    "* Who can create EC2 instances\n",
    "* What instance types they can use\n",
    "* Maximum resources allowed\n",
    "* Permissions on services\n",
    "\n",
    "### Example\n",
    "\n",
    "You can create IAM policy that:\n",
    "\n",
    "* Allows only `t3.medium` EC2 instances\n",
    "* Denies `m5.4xlarge`\n",
    "* Restricts region usage\n",
    "* Blocks certain configurations\n",
    "\n",
    "This is similar to:\n",
    "\n",
    "* Restricting VM type\n",
    "* Restricting size\n",
    "* Controlling cluster configuration\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ 2Ô∏è‚É£ Service Control Policies (For Organization Level)\n",
    "\n",
    "If company uses:\n",
    "\n",
    "## üëâ **AWS Organizations**\n",
    "\n",
    "You can create:\n",
    "\n",
    "* Service Control Policies (SCP)\n",
    "* Restrict entire accounts\n",
    "* Control maximum instance types globally\n",
    "\n",
    "This is like:\n",
    "\n",
    "* Company-wide guardrails\n",
    "* Prevent misuse across teams\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ 3Ô∏è‚É£ Service-Specific Controls (Example: EMR)\n",
    "\n",
    "If using:\n",
    "\n",
    "## üëâ **Amazon EMR**\n",
    "\n",
    "You can:\n",
    "\n",
    "* Restrict instance types\n",
    "* Control cluster size\n",
    "* Limit configurations via IAM + EMR settings\n",
    "\n",
    "That becomes closer to Databricks cluster policy.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Simple Comparison\n",
    "\n",
    "| Databricks                  | AWS Equivalent      |\n",
    "| --------------------------- | ------------------- |\n",
    "| Cluster Policy              | IAM Policy          |\n",
    "| Workspace-level restriction | IAM + SCP           |\n",
    "| Cluster config restriction  | EMR + IAM           |\n",
    "| Force auto-termination      | EC2 lifecycle + IAM |\n",
    "\n",
    "---\n",
    "\n",
    "# üß† In Simple Words\n",
    "\n",
    "Cluster Policy in DBX =\n",
    "üëâ Rules for cluster creation\n",
    "\n",
    "Equivalent in AWS =\n",
    "üëâ IAM Policies + SCP + Service-level restrictions\n",
    "\n",
    "AWS does not have a single ‚Äúcluster policy‚Äù feature.\n",
    "It uses **permission + governance model** instead.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also explain:\n",
    "\n",
    "* Equivalent in Azure\n",
    "* IAM vs SCP difference\n",
    "* Interview-style answer\n",
    "* Real-life architecture example üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20e0cd02-8d0f-41ba-80f3-48e51fd7906c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## What are **Notebooks in Databricks (DBX)?**\n",
    "\n",
    "**Notebooks in Databricks** are interactive web-based documents used to write, run, and document code for data engineering, data science, and analytics inside a Databricks workspace.\n",
    "\n",
    "They combine:\n",
    "\n",
    "* ‚úÖ Code\n",
    "* ‚úÖ Output (tables, charts)\n",
    "* ‚úÖ Markdown (documentation)\n",
    "\n",
    "---\n",
    "\n",
    "## What is a Notebook in DBX?\n",
    "\n",
    "A **Databricks notebook** is a collaborative development environment where you can:\n",
    "\n",
    "* Write code (Python, SQL, Scala, R)\n",
    "* Execute it on a cluster\n",
    "* Visualize results\n",
    "* Share with team members\n",
    "* Build data pipelines or ML models\n",
    "\n",
    "---\n",
    "\n",
    "## Supported Languages in Databricks Notebooks\n",
    "\n",
    "You can use:\n",
    "\n",
    "* **Python**\n",
    "* **SQL**\n",
    "* **Scala**\n",
    "* **R**\n",
    "\n",
    "You can even mix languages using magic commands like:\n",
    "\n",
    "```python\n",
    "%sql\n",
    "SELECT * FROM sales_table\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## How Companies Use Notebooks in Databricks\n",
    "\n",
    "Example in a company:\n",
    "\n",
    "### üîπ Data Engineer\n",
    "\n",
    "* Reads data from S3 / ADLS\n",
    "* Cleans & transforms data\n",
    "* Writes Delta tables\n",
    "\n",
    "### üîπ Data Analyst\n",
    "\n",
    "* Queries Delta tables using SQL\n",
    "* Creates dashboards\n",
    "\n",
    "### üîπ Data Scientist\n",
    "\n",
    "* Trains ML models\n",
    "* Tests algorithms\n",
    "* Saves models to MLflow\n",
    "\n",
    "All this happens inside notebooks.\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Architecture (How it Works)\n",
    "\n",
    "1. Notebook attaches to a **cluster**\n",
    "2. Cluster provides compute\n",
    "3. Code runs on cluster\n",
    "4. Results displayed in notebook\n",
    "\n",
    "If cluster stops ‚Üí notebook cannot run code.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Use Case\n",
    "\n",
    "Suppose a company stores raw sales data in S3.\n",
    "\n",
    "Notebook steps:\n",
    "\n",
    "1. Read raw CSV\n",
    "2. Clean data\n",
    "3. Save as Delta table\n",
    "4. Run SQL queries\n",
    "5. Visualize revenue trends\n",
    "\n",
    "All inside one notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features of Databricks Notebooks\n",
    "\n",
    "* Real-time collaboration (multiple users)\n",
    "* Version control integration (GitHub, Azure DevOps)\n",
    "* Job scheduling\n",
    "* Visualization tools\n",
    "* Markdown documentation\n",
    "* Supports widgets (parameters)\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook vs Traditional IDE\n",
    "\n",
    "| Notebook                | Traditional IDE               |\n",
    "| ----------------------- | ----------------------------- |\n",
    "| Interactive             | File-based                    |\n",
    "| Shows output inline     | Output separate               |\n",
    "| Collaborative           | Mostly single-user            |\n",
    "| Good for data workflows | Good for software development |\n",
    "\n",
    "---\n",
    "\n",
    "## Very Important Concept\n",
    "\n",
    "üëâ A Notebook is **not a database**\n",
    "üëâ It is a **development interface**\n",
    "üëâ It needs a cluster to run code\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* Notebook vs Jobs\n",
    "* Notebook vs Workspace\n",
    "* How notebooks are stored internally\n",
    "* Production best practices for notebooks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db7dce78-edcf-476d-8c12-ad317b87e53c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Do we have notebooks similar to DBX notebooks in AWS?\n",
    "\n",
    "Yes ‚úÖ ‚Äî **AWS provides notebook services similar to Databricks notebooks.**\n",
    "\n",
    "Here are the main ones:\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Amazon SageMaker Studio\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/sagemaker/latest/dg/images/studio/studio-home.png)\n",
    "\n",
    "![Image](https://sagemaker-example-files-prod-us-east-1.s3.amazonaws.com/images/sagemaker-studio-scheduling/overview.png)\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/sagemaker/latest/dg/images/studio-lab-ui.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/12/14/ML-16046-image001.jpg)\n",
    "\n",
    "### What it is:\n",
    "\n",
    "A fully managed ML development environment with Jupyter notebooks.\n",
    "\n",
    "### Similarities to Databricks:\n",
    "\n",
    "* Interactive notebooks\n",
    "* Python support\n",
    "* Attach compute\n",
    "* Visualization\n",
    "* Collaboration\n",
    "\n",
    "### Difference:\n",
    "\n",
    "* Focused more on **Machine Learning**\n",
    "* Not built primarily for big data engineering like Databricks\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Amazon EMR Studio\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2020/12/09/emr-studio-preview-6.jpg)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2023/10/31/BDB-3641_solution_arch-new.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2021/07/16/emr_eks_managed_endpoint_emr_studio_image_1-1.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2020/12/09/emr-studio-preview-1.jpg)\n",
    "\n",
    "### What it is:\n",
    "\n",
    "Notebook environment for running Spark jobs on EMR clusters.\n",
    "\n",
    "### Similarities to Databricks:\n",
    "\n",
    "* Run Spark\n",
    "* Attach to clusters\n",
    "* Data engineering workflows\n",
    "* Big data processing\n",
    "\n",
    "### This is the closest equivalent to Databricks notebooks in AWS.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Amazon Athena Notebook\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2022/10/03/Kepler-2.png)\n",
    "\n",
    "![Image](https://miro.medium.com/0%2AIkJ53fVGMZbTEGGQ.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/05/09/query-athena-sagemaker-8.gif)\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/athena/latest/ug/images/notebooks-spark-magics-1.png)\n",
    "\n",
    "### What it is:\n",
    "\n",
    "SQL-based notebook for querying data in S3.\n",
    "\n",
    "### Limitation:\n",
    "\n",
    "* SQL only\n",
    "* No Spark cluster\n",
    "* Not full data engineering environment\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Direct Comparison\n",
    "\n",
    "| Feature        | Databricks Notebook | SageMaker | EMR Studio |\n",
    "| -------------- | ------------------- | --------- | ---------- |\n",
    "| Big Data Spark | ‚úÖ Yes               | ‚ùå Limited | ‚úÖ Yes      |\n",
    "| ML Focus       | ‚úÖ Yes               | ‚úÖ Strong  | ‚ùå Basic    |\n",
    "| Collaboration  | ‚úÖ Strong            | Moderate  | Moderate   |\n",
    "| Delta Lake     | ‚úÖ Native            | ‚ùå No      | ‚ùå No       |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ So What Is AWS Equivalent to DBX Notebook?\n",
    "\n",
    "üëâ For **big data + Spark** ‚Üí **EMR Studio**\n",
    "üëâ For **machine learning** ‚Üí **SageMaker Studio**\n",
    "üëâ For **SQL on S3** ‚Üí **Athena Notebook**\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ Important Concept\n",
    "\n",
    "Databricks = Spark + Delta Lake + Notebook + Cluster management (all integrated)\n",
    "\n",
    "AWS = Separate services combined:\n",
    "\n",
    "* EMR (Spark)\n",
    "* S3 (Storage)\n",
    "* SageMaker (ML)\n",
    "* Athena (SQL)\n",
    "\n",
    "Databricks bundles everything in one platform.\n",
    "\n",
    "---\n",
    "\n",
    "If you want next, I can explain:\n",
    "\n",
    "* Is Databricks better than EMR?\n",
    "* Why companies still use Databricks on AWS?\n",
    "* Cost comparison between EMR and Databricks?\n",
    "* Architecture comparison diagram?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4bdc41f-c677-4d3e-bb30-87cbd1a7e1b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## What are Magic Commands in Notebook?\n",
    "\n",
    "**Magic commands in notebooks** are special commands that start with `%` or `%%` and allow you to perform actions outside normal programming syntax ‚Äî like switching languages, running shell commands, or configuring the environment.\n",
    "\n",
    "They are heavily used in **Databricks notebooks** and Jupyter notebooks.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Magic Commands in Databricks Notebooks\n",
    "\n",
    "In Databricks, magic commands help you:\n",
    "\n",
    "* Switch languages\n",
    "* Run SQL inside Python notebook\n",
    "* Call shell commands\n",
    "* Manage files\n",
    "* Use parameters (widgets)\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Language Magic Commands\n",
    "\n",
    "These allow you to mix languages inside one notebook.\n",
    "\n",
    "### Example:\n",
    "\n",
    "```python\n",
    "%sql\n",
    "SELECT * FROM sales;\n",
    "```\n",
    "\n",
    "Other language magics:\n",
    "\n",
    "* `%python`\n",
    "* `%sql`\n",
    "* `%scala`\n",
    "* `%r`\n",
    "\n",
    "üìå Very useful when:\n",
    "\n",
    "* Data engineer writes Python\n",
    "* Analyst writes SQL\n",
    "* Both work in same notebook\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ %run (Run Another Notebook)\n",
    "\n",
    "```python\n",
    "%run ./common_functions\n",
    "```\n",
    "\n",
    "Used to:\n",
    "\n",
    "* Import another notebook\n",
    "* Reuse code\n",
    "* Share functions across notebooks\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ %fs (File System Commands)\n",
    "\n",
    "Used to interact with DBFS (Databricks File System).\n",
    "\n",
    "```python\n",
    "%fs ls /mnt/data\n",
    "```\n",
    "\n",
    "You can:\n",
    "\n",
    "* List files\n",
    "* Copy files\n",
    "* Move files\n",
    "* Delete files\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ %sh (Shell Commands)\n",
    "\n",
    "Runs Linux commands inside notebook.\n",
    "\n",
    "```python\n",
    "%sh ls -l\n",
    "```\n",
    "\n",
    "Used for:\n",
    "\n",
    "* Installing libraries\n",
    "* Checking system files\n",
    "* Running bash scripts\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Widgets (Parameterization)\n",
    "\n",
    "```python\n",
    "dbutils.widgets.text(\"name\", \"default\")\n",
    "```\n",
    "\n",
    "Used to:\n",
    "\n",
    "* Pass parameters\n",
    "* Make notebook reusable\n",
    "* Use in scheduled jobs\n",
    "\n",
    "Example use case:\n",
    "\n",
    "* Same notebook runs for different dates\n",
    "* Pass date as parameter\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Difference Between % and %%\n",
    "\n",
    "| Symbol | Meaning                |\n",
    "| ------ | ---------------------- |\n",
    "| `%`    | Applies to one line    |\n",
    "| `%%`   | Applies to entire cell |\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "%%sql\n",
    "SELECT * FROM sales;\n",
    "SELECT * FROM customers;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Why Magic Commands Are Important\n",
    "\n",
    "Without magic:\n",
    "\n",
    "* You need separate scripts\n",
    "* Hard to mix SQL + Python\n",
    "* Harder automation\n",
    "\n",
    "With magic:\n",
    "\n",
    "* More interactive\n",
    "* Faster development\n",
    "* Easy collaboration\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ Real Company Example\n",
    "\n",
    "A data engineer:\n",
    "\n",
    "1. Uses `%sql` to explore data\n",
    "2. Uses `%python` to clean data\n",
    "3. Uses `%fs` to check files\n",
    "4. Uses widgets for daily pipeline\n",
    "\n",
    "All inside one notebook.\n",
    "\n",
    "---\n",
    "\n",
    "If you want next, I can explain:\n",
    "\n",
    "* Difference between %run and importing .py file\n",
    "* How magic commands work internally\n",
    "* Production best practices\n",
    "* Common interview questions on magic commands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6caf2ec-aa6f-40b4-9e49-686f5e2fdbb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Microsoft Azure Data Lake Storage (ADLS)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/architecture/data-guide/scenarios/images/data-lake-use-cases.jpg)\n",
    "\n",
    "![Image](https://azure.github.io/Storage/docs/analytics/azure-storage-data-lake-gen2-billing-faq/images/adls_hns.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/architecture/example-scenario/data/media/architecture-data-warehousing.svg)\n",
    "\n",
    "![Image](https://imgopt.infoq.com/fit-in/3000x4000/filters%3Aquality%2885%29/filters%3Ano_upscale%28%29/articles/azure-data-lake-analytics-usql/en/resources/azure-data-2-1568098316593.jpg)\n",
    "\n",
    "### What is Azure Data Lake Storage?\n",
    "\n",
    "**Azure Data Lake Storage (ADLS)** is a highly scalable, secure, and cost-effective cloud storage service from **Microsoft** designed specifically for **big data analytics workloads**.\n",
    "\n",
    "It allows you to store:\n",
    "\n",
    "* Structured data (tables, CSV)\n",
    "* Semi-structured data (JSON, XML, logs)\n",
    "* Unstructured data (images, videos, PDFs)\n",
    "\n",
    "ADLS is built on top of **Azure Blob Storage**, but optimized for analytics.\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ Versions of Azure Data Lake\n",
    "\n",
    "### üîπ ADLS Gen1 (Older ‚Äì mostly retired)\n",
    "\n",
    "* Purpose-built analytics storage\n",
    "* Limited integration\n",
    "* Not widely used today\n",
    "\n",
    "### üîπ ADLS Gen2 (Current & Industry Standard)\n",
    "\n",
    "Built on Azure Blob Storage + adds:\n",
    "\n",
    "* ‚úÖ Hierarchical namespace (like folders in Linux)\n",
    "* ‚úÖ Better performance for big data\n",
    "* ‚úÖ Lower cost\n",
    "* ‚úÖ Works natively with analytics engines\n",
    "\n",
    "üëâ Today when companies say *Azure Data Lake*, they usually mean **ADLS Gen2**.\n",
    "\n",
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ Core Features of ADLS Gen2\n",
    "\n",
    "### 1. Hierarchical Namespace\n",
    "\n",
    "Acts like a real file system:\n",
    "\n",
    "```\n",
    "/raw/sales/2026/jan/file1.csv\n",
    "/curated/sales/cleaned_data.parquet\n",
    "```\n",
    "\n",
    "This improves:\n",
    "\n",
    "* File management\n",
    "* Query performance\n",
    "* Big data processing efficiency\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Massive Scalability\n",
    "\n",
    "* Petabytes to exabytes of storage\n",
    "* Handles millions of files\n",
    "* Used in enterprise-scale environments\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Security & Governance\n",
    "\n",
    "* Azure Active Directory (AAD) integration\n",
    "* Role-Based Access Control (RBAC)\n",
    "* POSIX-style file permissions\n",
    "* Encryption at rest & in transit\n",
    "\n",
    "This makes it enterprise-ready.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Cost Optimization\n",
    "\n",
    "* Pay only for storage used\n",
    "* Multiple tiers:\n",
    "\n",
    "  * Hot (frequent access)\n",
    "  * Cool (less frequent)\n",
    "  * Archive (rare access)\n",
    "\n",
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ How ADLS Fits in Modern Data Architecture\n",
    "\n",
    "Typical Azure Big Data Architecture:\n",
    "\n",
    "```\n",
    "Data Sources ‚Üí ADLS ‚Üí Processing ‚Üí BI / ML\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "* Data sources ‚Üí ERP, CRM, IoT, logs\n",
    "* Stored in ‚Üí ADLS\n",
    "* Processed by ‚Üí\n",
    "\n",
    "  * Azure Databricks\n",
    "  * Azure Synapse Analytics\n",
    "  * Azure Data Factory\n",
    "* Visualized in ‚Üí Power BI\n",
    "\n",
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Industry Usage of ADLS\n",
    "\n",
    "## üè¶ Banking & Financial Services\n",
    "\n",
    "Use cases:\n",
    "\n",
    "* Fraud detection\n",
    "* Risk analytics\n",
    "* Regulatory reporting\n",
    "* Customer transaction history storage\n",
    "\n",
    "Example:\n",
    "A bank stores 10+ years of transaction data in ADLS.\n",
    "Databricks runs ML models on it for fraud detection.\n",
    "\n",
    "---\n",
    "\n",
    "## üè• Healthcare\n",
    "\n",
    "Use cases:\n",
    "\n",
    "* Patient records (de-identified)\n",
    "* Medical imaging storage\n",
    "* Clinical trial analytics\n",
    "\n",
    "Example:\n",
    "Hospitals store MRI scan data and use AI models for diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "## üõç Retail & E-commerce\n",
    "\n",
    "Use cases:\n",
    "\n",
    "* Customer clickstream data\n",
    "* Inventory analytics\n",
    "* Demand forecasting\n",
    "\n",
    "Example:\n",
    "An e-commerce company stores website logs in ADLS and predicts buying patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## üè≠ Manufacturing\n",
    "\n",
    "Use cases:\n",
    "\n",
    "* IoT sensor data\n",
    "* Predictive maintenance\n",
    "* Supply chain analytics\n",
    "\n",
    "Example:\n",
    "Factory sensors send data every second ‚Üí stored in ADLS ‚Üí ML predicts machine failure.\n",
    "\n",
    "---\n",
    "\n",
    "## üì° Telecom\n",
    "\n",
    "Use cases:\n",
    "\n",
    "* Call data records\n",
    "* Network optimization\n",
    "* Customer churn prediction\n",
    "\n",
    "Telecom companies store petabytes of call logs in ADLS.\n",
    "\n",
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ ADLS in Lakehouse Architecture\n",
    "\n",
    "With **Delta Lake + Databricks**, ADLS becomes the storage layer of a Lakehouse:\n",
    "\n",
    "```\n",
    "ADLS (Storage)\n",
    "   ‚Üì\n",
    "Delta Tables\n",
    "   ‚Üì\n",
    "Databricks (Processing)\n",
    "   ‚Üì\n",
    "BI / ML\n",
    "```\n",
    "\n",
    "This allows:\n",
    "\n",
    "* ACID transactions\n",
    "* Time travel\n",
    "* Schema enforcement\n",
    "\n",
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ Comparison with Traditional Data Warehouse\n",
    "\n",
    "| Feature     | ADLS           | Traditional DW    |\n",
    "| ----------- | -------------- | ----------------- |\n",
    "| Data Type   | Any format     | Mostly structured |\n",
    "| Scalability | Very high      | Limited           |\n",
    "| Cost        | Cheaper        | Expensive         |\n",
    "| Schema      | Schema-on-read | Schema-on-write   |\n",
    "| Use case    | Big data & AI  | Reporting         |\n",
    "\n",
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Real-World Enterprise Setup Example\n",
    "\n",
    "Large enterprise setup:\n",
    "\n",
    "* 3 environments:\n",
    "\n",
    "  * Dev ADLS\n",
    "  * Test ADLS\n",
    "  * Prod ADLS\n",
    "* Folder structure:\n",
    "\n",
    "  ```\n",
    "  raw/\n",
    "  processed/\n",
    "  curated/\n",
    "  sandbox/\n",
    "  ```\n",
    "* Data ingestion via Azure Data Factory\n",
    "* Processing via Databricks\n",
    "* Governance via Azure Purview\n",
    "\n",
    "---\n",
    "\n",
    "# 8Ô∏è‚É£ Why Companies Prefer ADLS\n",
    "\n",
    "‚úî Deep Azure integration\n",
    "‚úî Enterprise-grade security\n",
    "‚úî Cost-effective storage\n",
    "‚úî Works perfectly with Databricks\n",
    "‚úî Designed for analytics\n",
    "\n",
    "---\n",
    "\n",
    "# üîü Simple Explanation (Interview Style)\n",
    "\n",
    "‚ÄúAzure Data Lake Storage is scalable cloud storage optimized for big data analytics. It stores structured and unstructured data and acts as the foundation of modern data platforms in Azure. It is widely used in industries like banking, healthcare, retail, and manufacturing for analytics, AI, and reporting.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can next explain:\n",
    "\n",
    "* üî• ADLS vs S3 comparison\n",
    "* üî• ADLS + Databricks deep architecture\n",
    "* üî• How companies design folder structure in production\n",
    "* üî• Security model in detail\n",
    "* üî• Real-time streaming into ADLS\n",
    "\n",
    "Which one would you like?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12bd09e4-66a5-48d6-8bfd-d86fd531f189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üîê Encryption at Rest & In Transit (Azure Data Lake Storage)\n",
    "\n",
    "When using **Azure Data Lake Storage (ADLS Gen2)**, encryption protects your data in two stages:\n",
    "\n",
    "1Ô∏è‚É£ While it is **stored** ‚Üí *Encryption at Rest*\n",
    "2Ô∏è‚É£ While it is **moving over the network** ‚Üí *Encryption in Transit*\n",
    "\n",
    "Let‚Äôs break this down clearly.\n",
    "\n",
    "---\n",
    "\n",
    "# üîí 1Ô∏è‚É£ Encryption at Rest\n",
    "\n",
    "## What does it mean?\n",
    "\n",
    "**Encryption at Rest** means:\n",
    "\n",
    "> Data is encrypted while stored on disk inside Azure data centers.\n",
    "\n",
    "Even if:\n",
    "\n",
    "* Someone steals a physical disk\n",
    "* Storage hardware is compromised\n",
    "* A backup is accessed illegally\n",
    "\n",
    "The data is unreadable without the encryption key.\n",
    "\n",
    "---\n",
    "\n",
    "## How it works in ADLS\n",
    "\n",
    "Microsoft automatically encrypts all data in **Azure Data Lake Storage Gen2** using:\n",
    "\n",
    "* AES-256 encryption\n",
    "* Storage Service Encryption (SSE)\n",
    "* No extra configuration required\n",
    "\n",
    "Encryption happens:\n",
    "\n",
    "* Before data is written to disk\n",
    "* Automatically for all blobs/files\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Management Options\n",
    "\n",
    "### 1Ô∏è‚É£ Microsoft-Managed Keys (Default)\n",
    "\n",
    "* Azure handles keys\n",
    "* No management overhead\n",
    "* Suitable for most companies\n",
    "\n",
    "### 2Ô∏è‚É£ Customer-Managed Keys (CMK)\n",
    "\n",
    "Stored in:\n",
    "\n",
    "* Azure Key Vault\n",
    "\n",
    "Used when:\n",
    "\n",
    "* Regulatory compliance required\n",
    "* Financial institutions\n",
    "* Government organizations\n",
    "* Need full key rotation control\n",
    "\n",
    "---\n",
    "\n",
    "## üè¶ Industry Example (Bank)\n",
    "\n",
    "A bank stores 10 years of transaction history in ADLS.\n",
    "\n",
    "If a storage disk is physically stolen:\n",
    "\n",
    "* The data is encrypted\n",
    "* The thief cannot read anything\n",
    "* Without the encryption key, it‚Äôs useless\n",
    "\n",
    "That is encryption at rest.\n",
    "\n",
    "---\n",
    "\n",
    "# üåê 2Ô∏è‚É£ Encryption in Transit\n",
    "\n",
    "## What does it mean?\n",
    "\n",
    "**Encryption in Transit** means:\n",
    "\n",
    "> Data is encrypted while traveling between:\n",
    "\n",
    "* User ‚Üí ADLS\n",
    "* Databricks ‚Üí ADLS\n",
    "* Azure Data Factory ‚Üí ADLS\n",
    "* Any service ‚Üí ADLS\n",
    "\n",
    "---\n",
    "\n",
    "## How it works\n",
    "\n",
    "Azure enforces:\n",
    "\n",
    "* HTTPS (TLS 1.2+)\n",
    "* Secure communication channels\n",
    "\n",
    "If someone tries:\n",
    "\n",
    "* Packet sniffing\n",
    "* Man-in-the-middle attack\n",
    "* Network interception\n",
    "\n",
    "They see only encrypted data.\n",
    "\n",
    "---\n",
    "\n",
    "## üîê TLS (Transport Layer Security)\n",
    "\n",
    "TLS:\n",
    "\n",
    "* Encrypts data before sending\n",
    "* Decrypts at destination\n",
    "* Ensures integrity + authenticity\n",
    "\n",
    "Example:\n",
    "When your Databricks notebook reads from ADLS:\n",
    "\n",
    "```\n",
    "Databricks ‚Üí HTTPS ‚Üí ADLS\n",
    "```\n",
    "\n",
    "The data is encrypted while moving.\n",
    "\n",
    "---\n",
    "\n",
    "# üè≠ Industry Example (Healthcare)\n",
    "\n",
    "Hospital uploads MRI scan data from on-premise server to ADLS.\n",
    "\n",
    "Without encryption in transit:\n",
    "\n",
    "* Someone on the network could intercept medical data.\n",
    "\n",
    "With TLS:\n",
    "\n",
    "* The MRI file is encrypted during upload.\n",
    "* Even if intercepted ‚Üí unreadable.\n",
    "\n",
    "---\n",
    "\n",
    "# üîé Simple Visual\n",
    "\n",
    "```\n",
    "User ‚Üí (TLS encrypted) ‚Üí ADLS ‚Üí (AES-256 encrypted) ‚Üí Disk\n",
    "        ‚Üë In Transit            ‚Üë At Rest\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ Why Both Are Important\n",
    "\n",
    "| Scenario       | Protected By                |\n",
    "| -------------- | --------------------------- |\n",
    "| Disk theft     | Encryption at Rest          |\n",
    "| Network attack | Encryption in Transit       |\n",
    "| Insider misuse | RBAC + encryption           |\n",
    "| Data leak      | Encryption + Access control |\n",
    "\n",
    "---\n",
    "\n",
    "# üî• In Enterprise Architecture\n",
    "\n",
    "For compliance like:\n",
    "\n",
    "* HIPAA (Healthcare)\n",
    "* PCI-DSS (Banking)\n",
    "* GDPR (Europe)\n",
    "\n",
    "Both encryption types are mandatory.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Interview Answer (Short Version)\n",
    "\n",
    "‚ÄúEncryption at rest protects stored data using AES-256, while encryption in transit protects data movement using TLS. In Azure Data Lake Storage, both are enabled by default to ensure enterprise-grade security.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* üîë Double encryption\n",
    "* üîë Private endpoints vs public access\n",
    "* üîë How Databricks accesses ADLS securely\n",
    "* üîë Difference between encryption and hashing\n",
    "\n",
    "Which one?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f9cd69d-737e-4f61-8249-adbebd59f027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üî∑ Azure Databricks vs Azure Synapse vs Azure Data Factory\n",
    "\n",
    "(+ ADLS in Lakehouse Architecture)\n",
    "\n",
    "Let‚Äôs break this in a **clear architectural way** because in real companies all four are used together.\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ üî• Azure Databricks\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/architecture/solution-ideas/media/azure-databricks-modern-analytics-architecture.svg)\n",
    "\n",
    "![Image](https://res.cloudinary.com/endjin/image/upload/f_auto/q_80/assets/images/blog/2023/08/specifyingnotebookpath.png)\n",
    "\n",
    "![Image](https://docs.microsoft.com/en-us/learn/wwl-data-ai/spark-architecture-fundamentals/media/azure-databricks-architecture.png)\n",
    "\n",
    "![Image](https://www.databricks.com/sites/default/files/2019/03/Azure_Databricks_Default_Arch_Diagram-1-1.png)\n",
    "\n",
    "## What is it?\n",
    "\n",
    "A **big data processing & AI platform** built on Apache Spark.\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "> Heavy data processing + Machine Learning engine\n",
    "\n",
    "---\n",
    "\n",
    "## What it is used for\n",
    "\n",
    "* Data engineering (ETL at scale)\n",
    "* Streaming pipelines\n",
    "* Machine learning\n",
    "* Delta Lake processing\n",
    "* Advanced transformations\n",
    "\n",
    "---\n",
    "\n",
    "## Strengths\n",
    "\n",
    "‚úî Massive scale\n",
    "‚úî Best for complex transformations\n",
    "‚úî ML & AI ready\n",
    "‚úî Works natively with ADLS\n",
    "\n",
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "Retail company:\n",
    "\n",
    "* Stores raw clickstream data in ADLS\n",
    "* Databricks cleans and transforms it\n",
    "* Creates Delta tables\n",
    "* ML model predicts customer churn\n",
    "\n",
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ üè¢ Azure Synapse Analytics\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/media/overview-architecture/sql-architecture.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/media/sql-data-warehouse-overview-what-is/dedicated-sql-pool.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/synapse-analytics/media/overview-what-is/synapse-architecture.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/synapse-analytics/guidance/media/security-white-paper-network-security/private-link-hubs-for-synapse-studio.png)\n",
    "\n",
    "## What is it?\n",
    "\n",
    "Enterprise **data warehouse + analytics service**\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "> Structured reporting & BI engine\n",
    "\n",
    "---\n",
    "\n",
    "## What it is used for\n",
    "\n",
    "* SQL-based analytics\n",
    "* Enterprise reporting\n",
    "* Data warehousing\n",
    "* Power BI integration\n",
    "\n",
    "---\n",
    "\n",
    "## Strengths\n",
    "\n",
    "‚úî Strong SQL performance\n",
    "‚úî Best for BI teams\n",
    "‚úî Structured, governed reporting\n",
    "\n",
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "Bank:\n",
    "\n",
    "* Curated tables stored in ADLS\n",
    "* Synapse SQL pool queries the data\n",
    "* Finance team uses Power BI dashboards\n",
    "\n",
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ üîÑ Azure Data Factory\n",
    "\n",
    "![Image](https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/data/images/enterprise-bi-adf.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/data-factory/media/author-visually/properties-pane.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/data-factory/media/data-flow/dyna1.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/data-factory/media/data-flow/canvas-2.png)\n",
    "\n",
    "## What is it?\n",
    "\n",
    "A **data orchestration & movement tool**\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "> Data pipeline scheduler & mover\n",
    "\n",
    "---\n",
    "\n",
    "## What it is used for\n",
    "\n",
    "* Moving data (on-prem ‚Üí cloud)\n",
    "* Scheduling pipelines\n",
    "* Orchestrating workflows\n",
    "* Triggering Databricks jobs\n",
    "\n",
    "---\n",
    "\n",
    "## Strengths\n",
    "\n",
    "‚úî Connects 100+ data sources\n",
    "‚úî No-code pipeline design\n",
    "‚úî Enterprise scheduling\n",
    "\n",
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "Manufacturing company:\n",
    "\n",
    "* ADF copies SAP data to ADLS every night\n",
    "* Triggers Databricks job after copy\n",
    "* Sends success notification\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Quick Comparison Table\n",
    "\n",
    "| Feature      | Databricks           | Synapse        | Data Factory        |\n",
    "| ------------ | -------------------- | -------------- | ------------------- |\n",
    "| Main Purpose | Data Processing & ML | Data Warehouse | Data Movement       |\n",
    "| Engine       | Spark                | SQL            | Orchestration       |\n",
    "| Best For     | Big data engineering | BI reporting   | Pipeline automation |\n",
    "| ML Support   | Yes                  | Limited        | No                  |\n",
    "| SQL Support  | Yes                  | Strong         | Basic               |\n",
    "\n",
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ üèó ADLS in Lakehouse Architecture\n",
    "\n",
    "## What is Lakehouse?\n",
    "\n",
    "Lakehouse =\n",
    "Data Lake + Data Warehouse features together\n",
    "\n",
    "Storage = ADLS\n",
    "Processing = Databricks\n",
    "SQL + BI = Synapse\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Flow\n",
    "\n",
    "```\n",
    "        Data Sources\n",
    "            ‚Üì\n",
    "      Azure Data Factory\n",
    "            ‚Üì\n",
    "        ADLS (Storage Layer)\n",
    "            ‚Üì\n",
    "      Databricks (Processing)\n",
    "            ‚Üì\n",
    "      Delta Tables (Lakehouse)\n",
    "            ‚Üì\n",
    "     Synapse / Power BI\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Role of ADLS\n",
    "\n",
    "ADLS acts as:\n",
    "\n",
    "### 1Ô∏è‚É£ Central Storage Layer\n",
    "\n",
    "* Raw data\n",
    "* Processed data\n",
    "* Curated data\n",
    "* Delta tables\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Supports Medallion Architecture\n",
    "\n",
    "```\n",
    "Bronze ‚Üí Silver ‚Üí Gold\n",
    "```\n",
    "\n",
    "* Bronze = Raw data\n",
    "* Silver = Cleaned data\n",
    "* Gold = Business-ready data\n",
    "\n",
    "All stored inside ADLS.\n",
    "\n",
    "---\n",
    "\n",
    "## Why ADLS is Important in Lakehouse\n",
    "\n",
    "‚úî Cheap storage\n",
    "‚úî Scalable\n",
    "‚úî Works with Spark\n",
    "‚úî Supports Delta Lake\n",
    "‚úî Enterprise security\n",
    "\n",
    "Without ADLS ‚Üí No Lakehouse foundation.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Real Enterprise Example\n",
    "\n",
    "Large Retail Company:\n",
    "\n",
    "1. Data Factory ingests data\n",
    "2. Stored in ADLS Bronze layer\n",
    "3. Databricks cleans ‚Üí Silver\n",
    "4. Business aggregates ‚Üí Gold\n",
    "5. Synapse queries Gold tables\n",
    "6. Power BI dashboards built on Synapse\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Simple Interview Explanation\n",
    "\n",
    "* Azure Data Factory ‚Üí Moves data\n",
    "* Azure Databricks ‚Üí Processes data\n",
    "* Azure Synapse ‚Üí Reports on data\n",
    "* ADLS ‚Üí Stores everything\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* üî• When to choose Synapse over Databricks\n",
    "* üî• Databricks vs Synapse Spark difference\n",
    "* üî• Complete Azure end-to-end architecture\n",
    "* üî• Cost comparison\n",
    "* üî• Real enterprise environment setup (Dev/Test/Prod)\n",
    "\n",
    "Which one?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f381a52-c9a9-4246-b65e-0fbb70d3b2fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is a **very important conceptual difference** üëá ‚Äî many people confuse these.\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ Lakehouse vs Delta Tables\n",
    "\n",
    "## üèó What is a Lakehouse?\n",
    "\n",
    "A **Lakehouse** is an **architecture pattern**.\n",
    "\n",
    "It combines:\n",
    "\n",
    "* Data Lake flexibility\n",
    "* Data Warehouse reliability (ACID, governance, performance)\n",
    "\n",
    "In Azure, a typical Lakehouse stack is:\n",
    "\n",
    "* Storage ‚Üí Azure Data Lake Storage\n",
    "* Processing ‚Üí Azure Databricks\n",
    "* Format ‚Üí Delta Lake\n",
    "\n",
    "üëâ So Lakehouse = **overall design approach**\n",
    "\n",
    "---\n",
    "\n",
    "## üß± What are Delta Tables?\n",
    "\n",
    "Delta Tables are **actual physical tables** stored using Delta Lake format.\n",
    "\n",
    "They provide:\n",
    "\n",
    "* ACID transactions\n",
    "* Schema enforcement\n",
    "* Time travel\n",
    "* Upserts (MERGE)\n",
    "* Versioning\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "/mnt/adls/gold/sales_delta/\n",
    "```\n",
    "\n",
    "That folder contains:\n",
    "\n",
    "* Data files (Parquet)\n",
    "* _delta_log (transaction log)\n",
    "\n",
    "That is a Delta Table.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Simple Difference\n",
    "\n",
    "| Lakehouse            | Delta Tables          |\n",
    "| -------------------- | --------------------- |\n",
    "| Architecture concept | Storage format        |\n",
    "| Big-picture design   | Actual implementation |\n",
    "| Uses ADLS            | Stored inside ADLS    |\n",
    "| Uses Delta tables    | Are Delta tables      |\n",
    "\n",
    "üëâ Lakehouse uses Delta Tables.\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ Lakehouse Architecture vs Medallion Architecture\n",
    "\n",
    "These are also different layers of thinking.\n",
    "\n",
    "---\n",
    "\n",
    "# üèó 1Ô∏è‚É£ Lakehouse Architecture\n",
    "\n",
    "Lakehouse defines **how the whole system is built**.\n",
    "\n",
    "### Components:\n",
    "\n",
    "```\n",
    "Data Sources\n",
    "     ‚Üì\n",
    "Ingestion (ADF)\n",
    "     ‚Üì\n",
    "Storage (ADLS)\n",
    "     ‚Üì\n",
    "Processing (Databricks)\n",
    "     ‚Üì\n",
    "Serving (Synapse / Power BI)\n",
    "```\n",
    "\n",
    "It answers:\n",
    "\n",
    "* Where is data stored?\n",
    "* What engine processes it?\n",
    "* How is BI done?\n",
    "* How governance works?\n",
    "\n",
    "üëâ It is system-level architecture.\n",
    "\n",
    "---\n",
    "\n",
    "# ü•á 2Ô∏è‚É£ Medallion Architecture\n",
    "\n",
    "Medallion Architecture defines **how data is organized inside the Lakehouse**.\n",
    "\n",
    "It focuses on data quality layers.\n",
    "\n",
    "---\n",
    "\n",
    "## ü•â Bronze Layer\n",
    "\n",
    "* Raw data\n",
    "* No transformation\n",
    "* Exact copy from source\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "/bronze/sales/raw_2026.csv\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ü•à Silver Layer\n",
    "\n",
    "* Cleaned\n",
    "* Deduplicated\n",
    "* Standardized\n",
    "* Joined\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "/silver/sales_cleaned_delta/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ü•á Gold Layer\n",
    "\n",
    "* Business-ready\n",
    "* Aggregated\n",
    "* KPI tables\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "/gold/sales_summary_delta/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Visual Representation\n",
    "\n",
    "```\n",
    "         Lakehouse Architecture\n",
    "------------------------------------------------\n",
    "  ADLS (Storage)\n",
    "     ‚îú‚îÄ‚îÄ Bronze\n",
    "     ‚îú‚îÄ‚îÄ Silver\n",
    "     ‚îî‚îÄ‚îÄ Gold\n",
    "------------------------------------------------\n",
    "```\n",
    "\n",
    "Lakehouse = The house\n",
    "Medallion = The room organization inside the house\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Key Differences\n",
    "\n",
    "| Lakehouse Architecture   | Medallion Architecture         |\n",
    "| ------------------------ | ------------------------------ |\n",
    "| System-level design      | Data organization pattern      |\n",
    "| Includes tools & storage | Focuses on data layers         |\n",
    "| Uses ADLS, Databricks    | Defines Bronze/Silver/Gold     |\n",
    "| Enterprise architecture  | Data engineering best practice |\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Real Enterprise Example\n",
    "\n",
    "Retail company:\n",
    "\n",
    "### Lakehouse Architecture:\n",
    "\n",
    "* ADLS for storage\n",
    "* Databricks for processing\n",
    "* Synapse for reporting\n",
    "\n",
    "### Medallion Implementation:\n",
    "\n",
    "* Bronze ‚Üí Raw clickstream\n",
    "* Silver ‚Üí Cleaned customer sessions\n",
    "* Gold ‚Üí Daily revenue table\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Interview-Ready Explanation\n",
    "\n",
    "‚ÄúLakehouse is an architecture combining data lake and warehouse capabilities. Delta tables are the storage format used inside the lakehouse. Medallion architecture is a data organization pattern inside the lakehouse that divides data into Bronze, Silver, and Gold layers.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* üî• Why Delta tables are better than Parquet\n",
    "* üî• How MERGE works internally\n",
    "* üî• Lakehouse vs Data Warehouse detailed comparison\n",
    "* üî• Unity Catalog role in Lakehouse\n",
    "* üî• Real production folder structure example\n",
    "\n",
    "Which one?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3228147-83fd-4358-b8fd-d40852086499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Great question üëå ‚Äî this is where many people get confused.\n",
    "\n",
    "# ‚ùì Do we have a separate Azure service for Delta Lake?\n",
    "\n",
    "üëâ **No. There is no separate Azure service called ‚ÄúDelta Lake.‚Äù**\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ What Exactly Is Delta Lake?\n",
    "\n",
    "Delta Lake is:\n",
    "\n",
    "* An **open-source storage framework**\n",
    "* Not a standalone Azure service\n",
    "* Not something you deploy separately like ADLS\n",
    "\n",
    "It is a **software layer** that runs on top of cloud storage like:\n",
    "\n",
    "* Azure Data Lake Storage\n",
    "* Amazon S3\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ Then How Do We Use Delta Lake in Azure?\n",
    "\n",
    "You use it through compute engines that support Delta format.\n",
    "\n",
    "Most common in Azure:\n",
    "\n",
    "* Azure Databricks\n",
    "* Azure Synapse Analytics (Spark pools)\n",
    "\n",
    "These engines:\n",
    "\n",
    "* Read/write Delta tables\n",
    "* Maintain `_delta_log`\n",
    "* Handle transactions\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ What Actually Stores Delta Tables?\n",
    "\n",
    "The storage is still:\n",
    "\n",
    "üëâ Azure Data Lake Storage (ADLS)\n",
    "\n",
    "Example folder:\n",
    "\n",
    "```\n",
    "/gold/sales_delta/\n",
    "    ‚îú‚îÄ‚îÄ part-0001.parquet\n",
    "    ‚îú‚îÄ‚îÄ part-0002.parquet\n",
    "    ‚îî‚îÄ‚îÄ _delta_log/\n",
    "```\n",
    "\n",
    "There is no ‚ÄúDelta Lake service‚Äù running separately.\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ So What Is Databricks Doing?\n",
    "\n",
    "Databricks:\n",
    "\n",
    "* Created Delta Lake\n",
    "* Provides built-in Delta support\n",
    "* Automatically manages transaction logs\n",
    "* Optimizes performance\n",
    "\n",
    "But Delta Lake itself:\n",
    "\n",
    "* Is open source\n",
    "* Can run outside Databricks too\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ When People Say ‚ÄúWe Are Using Delta Lake‚Äù\n",
    "\n",
    "They usually mean:\n",
    "\n",
    "* We store data in ADLS\n",
    "* We use Delta format tables\n",
    "* We process with Databricks or Spark\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Important Clarification\n",
    "\n",
    "| Item                    | Is it a separate Azure service? |\n",
    "| ----------------------- | ------------------------------- |\n",
    "| Azure Data Lake Storage | ‚úÖ Yes                           |\n",
    "| Azure Databricks        | ‚úÖ Yes                           |\n",
    "| Delta Lake              | ‚ùå No                            |\n",
    "| Delta Tables            | ‚ùå No (just format)              |\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Simple Interview Answer\n",
    "\n",
    "‚ÄúNo, Delta Lake is not a separate Azure service. It is an open-source storage layer that runs on top of cloud storage like ADLS and is accessed through engines like Databricks or Synapse Spark.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* üî• How Delta transaction log works internally\n",
    "* üî• How Delta ensures ACID on object storage\n",
    "* üî• Why Delta is better than plain Parquet\n",
    "* üî• How Delta compares with Iceberg\n",
    "\n",
    "What should we explore next?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f2c9e7e-c9c8-49c8-9b6f-ee252d29398f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Good üëç this is the exact foundation concept.\n",
    "\n",
    "# ‚ùì What does ‚ÄúDelta format tables‚Äù mean?\n",
    "\n",
    "üëâ **Delta format table = A table stored in Delta Lake format instead of plain Parquet or CSV.**\n",
    "\n",
    "It is still stored in your data lake (like ADLS), but with extra transaction metadata.\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ Where Is It Stored?\n",
    "\n",
    "Usually in:\n",
    "\n",
    "* Azure Data Lake Storage\n",
    "  or\n",
    "* Amazon S3\n",
    "\n",
    "Delta format does NOT change the storage service.\n",
    "It changes how the data is organized and managed.\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ What Does a Delta Table Folder Look Like?\n",
    "\n",
    "If you go inside the storage path, you will see something like:\n",
    "\n",
    "```\n",
    "/sales_delta/\n",
    "   ‚îú‚îÄ‚îÄ part-0001.parquet\n",
    "   ‚îú‚îÄ‚îÄ part-0002.parquet\n",
    "   ‚îú‚îÄ‚îÄ part-0003.parquet\n",
    "   ‚îî‚îÄ‚îÄ _delta_log/\n",
    "```\n",
    "\n",
    "### Important:\n",
    "\n",
    "* The data files are still **Parquet**\n",
    "* The `_delta_log` folder makes it a **Delta table**\n",
    "\n",
    "That `_delta_log` folder contains:\n",
    "\n",
    "* Transaction history\n",
    "* Schema info\n",
    "* Version metadata\n",
    "* Commit logs\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ Without Delta Format\n",
    "\n",
    "If you store only Parquet:\n",
    "\n",
    "```\n",
    "/sales/\n",
    "   ‚îú‚îÄ‚îÄ file1.parquet\n",
    "   ‚îú‚îÄ‚îÄ file2.parquet\n",
    "```\n",
    "\n",
    "Problems:\n",
    "\n",
    "* No transaction tracking\n",
    "* No versioning\n",
    "* No safe updates\n",
    "* Risk of corruption during write\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ With Delta Format\n",
    "\n",
    "Delta adds:\n",
    "\n",
    "‚úî ACID transactions\n",
    "‚úî Schema enforcement\n",
    "‚úî Time travel\n",
    "‚úî MERGE (upsert)\n",
    "‚úî Safe concurrent writes\n",
    "\n",
    "---\n",
    "\n",
    "# üî• What Makes It ‚ÄúDelta Format‚Äù?\n",
    "\n",
    "It becomes Delta format when:\n",
    "\n",
    "1. Data is written using Delta Lake engine\n",
    "2. `_delta_log` folder is created\n",
    "3. Metadata is maintained for every change\n",
    "\n",
    "Usually written using:\n",
    "\n",
    "* Azure Databricks\n",
    "* Spark with Delta Lake libraries\n",
    "\n",
    "Example in Spark:\n",
    "\n",
    "```\n",
    "df.write.format(\"delta\").save(\"/mnt/adls/sales_delta\")\n",
    "```\n",
    "\n",
    "That creates a Delta format table.\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ Simple Comparison\n",
    "\n",
    "| Feature          | Parquet Table | Delta Format Table        |\n",
    "| ---------------- | ------------- | ------------------------- |\n",
    "| File Type        | Parquet       | Parquet + transaction log |\n",
    "| ACID             | ‚ùå No          | ‚úÖ Yes                     |\n",
    "| Time Travel      | ‚ùå No          | ‚úÖ Yes                     |\n",
    "| Updates          | Difficult     | Easy (MERGE)              |\n",
    "| Production Ready | Risky         | Enterprise safe           |\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Simple Analogy\n",
    "\n",
    "* Parquet table = Excel file on shared drive\n",
    "* Delta table = Excel file with version control + locking + history\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Interview-Ready Answer\n",
    "\n",
    "‚ÄúDelta format tables are tables stored in Parquet files along with a transaction log (_delta_log) that enables ACID transactions, schema enforcement, and time travel on top of a data lake.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "If you'd like, next I can explain:\n",
    "\n",
    "* üî• What happens inside `_delta_log`\n",
    "* üî• How Delta enables ACID on object storage\n",
    "* üî• How MERGE works internally\n",
    "* üî• Delta vs Iceberg\n",
    "\n",
    "What should we go deeper into?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8416f36-a4a5-4ec5-98e7-8d48f6cafd0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is a **small but very important distinction** üëá\n",
    "\n",
    "Many people use these terms interchangeably ‚Äî but they are not exactly the same.\n",
    "\n",
    "---\n",
    "\n",
    "# üî∑ Delta Lake vs Delta Table\n",
    "\n",
    "## 1Ô∏è‚É£ What is Delta Lake?\n",
    "\n",
    "Delta Lake is:\n",
    "\n",
    "> The **technology / storage framework** that adds reliability features on top of a data lake.\n",
    "\n",
    "It provides:\n",
    "\n",
    "* ACID transactions\n",
    "* Schema enforcement\n",
    "* Time travel\n",
    "* Version control\n",
    "* MERGE (upsert)\n",
    "* Concurrent write handling\n",
    "\n",
    "It works on top of storage like:\n",
    "\n",
    "* Azure Data Lake Storage\n",
    "* Amazon S3\n",
    "\n",
    "üëâ Think of Delta Lake as the **engine + rules + transaction system**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ What is a Delta Table?\n",
    "\n",
    "A **Delta Table** is:\n",
    "\n",
    "> An actual table stored using Delta Lake format.\n",
    "\n",
    "It is a folder inside your data lake that contains:\n",
    "\n",
    "```\n",
    "/sales_delta/\n",
    "   ‚îú‚îÄ‚îÄ part-0001.parquet\n",
    "   ‚îú‚îÄ‚îÄ part-0002.parquet\n",
    "   ‚îî‚îÄ‚îÄ _delta_log/\n",
    "```\n",
    "\n",
    "The `_delta_log` folder is what makes it a Delta table.\n",
    "\n",
    "üëâ It is the **implementation/output of Delta Lake**.\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Simple Relationship\n",
    "\n",
    "* Delta Lake = Technology\n",
    "* Delta Table = Table created using that technology\n",
    "\n",
    "---\n",
    "\n",
    "# üîé Real-World Example\n",
    "\n",
    "Let‚Äôs say you are using:\n",
    "\n",
    "* Storage ‚Üí ADLS\n",
    "* Processing ‚Üí Azure Databricks\n",
    "\n",
    "When you run:\n",
    "\n",
    "```\n",
    "df.write.format(\"delta\").save(\"/mnt/adls/sales\")\n",
    "```\n",
    "\n",
    "What happens?\n",
    "\n",
    "* Delta Lake framework handles transactions\n",
    "* A folder is created in ADLS\n",
    "* `_delta_log` is created\n",
    "* Data files are written\n",
    "\n",
    "That folder is now a **Delta table**.\n",
    "\n",
    "---\n",
    "\n",
    "# üèó Analogy\n",
    "\n",
    "Think of it like:\n",
    "\n",
    "* Delta Lake = Microsoft SQL Server software\n",
    "* Delta Table = A table created inside SQL Server\n",
    "\n",
    "OR\n",
    "\n",
    "* Delta Lake = Rules of a banking system\n",
    "* Delta Table = A specific bank account\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Comparison Table\n",
    "\n",
    "| Delta Lake             | Delta Table                     |\n",
    "| ---------------------- | ------------------------------- |\n",
    "| Technology/framework   | Actual stored table             |\n",
    "| Provides ACID features | Uses those ACID features        |\n",
    "| Works on ADLS/S3       | Stored inside ADLS/S3           |\n",
    "| Concept/system         | Physical folder with _delta_log |\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Interview-Ready Answer\n",
    "\n",
    "‚ÄúDelta Lake is the open-source storage framework that adds ACID transactions and reliability to a data lake. A Delta table is an actual table stored using Delta Lake format.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next we can go deeper into:\n",
    "\n",
    "* üî• How Delta transaction log works internally\n",
    "* üî• How Delta ensures ACID on object storage\n",
    "* üî• Delta vs Iceberg vs Hudi\n",
    "* üî• Why Delta is critical in Lakehouse\n",
    "\n",
    "Which direction do you want to go?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f16410ad-1ba4-4fe3-935a-c4dc407b5280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Are ADLS Containers Equivalent to Buckets in AWS S3?\n",
    "\n",
    "### Short Answer:\n",
    "\n",
    "üëâ **Yes ‚Äî ADLS containers are conceptually equivalent to S3 buckets**, but there are some architectural differences.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∑ Azure Side: ADLS Gen2\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/common-data-model/media/cdm-data-lake-2.png)\n",
    "\n",
    "![Image](https://microsoftlearning.github.io/AZ-104-MicrosoftAzureAdministrator/Instructions/media/az104-lab07-architecture.png)\n",
    "\n",
    "![Image](https://azure.github.io/Storage/docs/analytics/azure-storage-data-lake-gen2-billing-faq/images/adls_hns.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/storage/blobs/media/create-data-lake-storage-account/hierarchical-namespace-feature.png)\n",
    "\n",
    "In Azure Data Lake Storage (ADLS Gen2):\n",
    "\n",
    "Structure:\n",
    "\n",
    "```\n",
    "Storage Account\n",
    "   ‚îî‚îÄ‚îÄ Container\n",
    "          ‚îî‚îÄ‚îÄ Folders\n",
    "                ‚îî‚îÄ‚îÄ Files\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "mystorageaccount\n",
    "   ‚îî‚îÄ‚îÄ raw-data\n",
    "         ‚îî‚îÄ‚îÄ 2025/\n",
    "               ‚îî‚îÄ‚îÄ sales.csv\n",
    "```\n",
    "\n",
    "* **Storage Account** = top-level resource\n",
    "* **Container** = logical storage unit\n",
    "* Supports **hierarchical namespace** (real folders)\n",
    "\n",
    "---\n",
    "\n",
    "## üî∑ AWS Side: S3\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2021/08/02/Fig1-S3-Object.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2016/10/12/ParquetRename.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2022/05/23/S3AddsDeletionAndPrefixFiltering.png)\n",
    "\n",
    "![Image](https://www.hava.io/hs-fs/hubfs/S3_bucket.png?name=S3_bucket.png\\&width=2338)\n",
    "\n",
    "In Amazon S3:\n",
    "\n",
    "Structure:\n",
    "\n",
    "```\n",
    "Bucket\n",
    "   ‚îî‚îÄ‚îÄ Objects (with prefixes)\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "my-bucket\n",
    "   ‚îî‚îÄ‚îÄ raw-data/2025/sales.csv\n",
    "```\n",
    "\n",
    "* **Bucket** = top-level storage container\n",
    "* Folders are not real folders (just prefixes)\n",
    "* Fully object storage (no hierarchical namespace by default)\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Direct Comparison\n",
    "\n",
    "| Feature                  | ADLS Container                 | S3 Bucket           |\n",
    "| ------------------------ | ------------------------------ | ------------------- |\n",
    "| Top-level storage unit   | ‚ùå (Storage Account is top)     | ‚úÖ Yes               |\n",
    "| Logical storage grouping | ‚úÖ Yes                          | ‚úÖ Yes               |\n",
    "| Real folder structure    | ‚úÖ Yes (Hierarchical namespace) | ‚ùå No (prefix-based) |\n",
    "| Access control           | RBAC + ACLs                    | IAM policies        |\n",
    "| Used with Databricks     | Yes                            | Yes                 |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Key Difference\n",
    "\n",
    "### üîπ In Azure:\n",
    "\n",
    "You create:\n",
    "\n",
    "```\n",
    "Storage Account ‚Üí Container\n",
    "```\n",
    "\n",
    "### üîπ In AWS:\n",
    "\n",
    "You directly create:\n",
    "\n",
    "```\n",
    "Bucket\n",
    "```\n",
    "\n",
    "So technically:\n",
    "\n",
    "> üîµ **ADLS Container ‚âà S3 Bucket**\n",
    "> But Storage Account layer exists in Azure.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† In Databricks Context\n",
    "\n",
    "When using:\n",
    "\n",
    "* Azure Databricks ‚Üí you mount ADLS containers\n",
    "* Databricks on AWS ‚Üí you connect to S3 buckets\n",
    "\n",
    "---\n",
    "\n",
    "# üí° Real Industry Mapping Example\n",
    "\n",
    "If a company migrates from AWS to Azure:\n",
    "\n",
    "| AWS        | Azure Equivalent |\n",
    "| ---------- | ---------------- |\n",
    "| S3 Bucket  | ADLS Container   |\n",
    "| IAM Policy | RBAC + ACL       |\n",
    "| S3 Object  | Blob/File        |\n",
    "\n",
    "---\n",
    "\n",
    "# üèÅ Final One-Line Answer\n",
    "\n",
    "üëâ **Yes, ADLS containers are functionally equivalent to S3 buckets, but Azure adds a Storage Account layer above containers.**\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* Storage Account vs Container in detail\n",
    "* ADLS Gen2 vs S3 performance differences\n",
    "* IAM vs RBAC comparison\n",
    "* How Databricks connects to both\n",
    "\n",
    "Which one?\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dbx_notes",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python (cs465cs565)",
   "language": "python",
   "name": "cs465cs565"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
