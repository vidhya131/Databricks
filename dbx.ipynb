{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e1106ca-01f1-4a70-95b1-ac803bc213d8",
   "metadata": {},
   "source": [
    "## East US (Azure Region)\n",
    "\n",
    "![Image](https://agileit.com/_astro/az-graphic-two.C0qDynBR.png)\n",
    "\n",
    "![Image](https://www.datacenters.com/_next/image?q=75\\&url=https%3A%2F%2Fres.cloudinary.com%2Fhjlz68xhm%2Fimage%2Fupload%2Fmhwxlsnsdld0vqc4nc4p\\&w=384)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/route-server/media/multiregion/multiregion.png)\n",
    "\n",
    "![Image](https://sparxsystems.com/resources/gallery/diagrams/images/multi-region-web-app.png)\n",
    "\n",
    "**East US has 3 Availability Zones (AZs).**\n",
    "\n",
    "### What that means:\n",
    "\n",
    "* ‚úÖ **3 physically separate datacenter locations**\n",
    "* ‚úÖ Independent power, cooling, and networking\n",
    "* ‚úÖ Low-latency connection between zones (typically < 2 ms)\n",
    "* ‚úÖ Designed for high availability and zone-redundant deployments\n",
    "\n",
    "You can deploy:\n",
    "\n",
    "* Zone-redundant services (like ZRS storage)\n",
    "* Zone-pinned VMs\n",
    "* Multi-AZ architectures for 99.99%+ uptime designs\n",
    "\n",
    "If you want, tell me what service you're planning (VM, AKS, SQL, etc.) and I‚Äôll explain how AZ works for that specifically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6e5fb-ddae-4a7c-9cd8-27fb2ec88caf",
   "metadata": {},
   "source": [
    "## Why Availability Zones (AZs) are needed in East US\n",
    "\n",
    "![Image](https://agileit.com/_astro/az-graphic-two.C0qDynBR.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/architecture/high-availability/images/high-availability-multi-region-web-v-10.png)\n",
    "\n",
    "![Image](https://ih1.dpstele.com/images/power-outage.webp)\n",
    "\n",
    "![Image](https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4fn80cCKCVWYn0XOOh3eX2/e23f4144cdb106dc80bd3b8a27f27254/image3-11.png)\n",
    "\n",
    "Availability Zones exist for **high availability and fault tolerance**.\n",
    "\n",
    "A single data center can fail. An AZ design protects you from that.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß What problem do AZs solve?\n",
    "\n",
    "### 1Ô∏è‚É£ Data center failures happen\n",
    "\n",
    "Even hyperscale facilities can experience:\n",
    "\n",
    "* Power outages\n",
    "* Cooling failures\n",
    "* Network outages\n",
    "* Hardware failures\n",
    "* Natural disasters\n",
    "\n",
    "If everything runs in one building ‚Üí your app goes down.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ AZs isolate failure domains\n",
    "\n",
    "Each Availability Zone:\n",
    "\n",
    "* Is a **separate physical location**\n",
    "* Has independent **power, cooling, networking**\n",
    "* Is connected with **low-latency private fiber**\n",
    "\n",
    "If Zone 1 fails ‚Üí Zones 2 and 3 keep running.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Enables High Availability Architectures\n",
    "\n",
    "With 3 AZs in East US, you can:\n",
    "\n",
    "* Run VMs in multiple zones\n",
    "* Use zone-redundant storage (ZRS)\n",
    "* Deploy AKS node pools across zones\n",
    "* Use load balancers across zones\n",
    "\n",
    "This helps achieve:\n",
    "\n",
    "* 99.99%+ uptime\n",
    "* Better SLA guarantees\n",
    "* Resilience for production systems\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Simple analogy\n",
    "\n",
    "Think of AZs like:\n",
    "\n",
    "* Not storing all your money in one bank branch\n",
    "* Not hosting your entire company in one building\n",
    "\n",
    "If one location burns down, you don‚Äôt lose everything.\n",
    "\n",
    "---\n",
    "\n",
    "## When do you really need AZ?\n",
    "\n",
    "AZ is critical for:\n",
    "\n",
    "* Production workloads\n",
    "* Customer-facing apps\n",
    "* Financial systems\n",
    "* Healthcare systems\n",
    "* E-commerce platforms\n",
    "\n",
    "For dev/test environments?\n",
    "Usually not necessary.\n",
    "\n",
    "---\n",
    "\n",
    "If you'd like, tell me what you're building and I‚Äôll tell you whether you *actually* need multi-AZ or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d9ff0-e8fa-485f-bed0-038d4f6ec274",
   "metadata": {},
   "source": [
    "This is one of the most confusing topics in Databricks ‚Äî let‚Äôs make it very clear üëå\n",
    "\n",
    "---\n",
    "\n",
    "# üèû 1Ô∏è‚É£ Data Lake\n",
    "\n",
    "![Image](https://miro.medium.com/1%2AHp24J2YlyW6oe9skN6gVYw.png)\n",
    "\n",
    "![Image](https://www.altexsoft.com/static/blog-post/2024/4/984d355c-0793-4051-9c61-d8237412fdc6.jpg)\n",
    "\n",
    "![Image](https://images.prismic.io/encord/ZgWeSMt2UUcvBQo1_image3.png?auto=format%2Ccompress)\n",
    "\n",
    "![Image](https://azure.github.io/Storage/docs/analytics/hitchhikers-guide-to-the-datalake/images/data_lake_zones.png)\n",
    "\n",
    "A **Data Lake** is just **storage**.\n",
    "\n",
    "It stores:\n",
    "\n",
    "* CSV files\n",
    "* JSON files\n",
    "* Parquet files\n",
    "* Images\n",
    "* Logs\n",
    "* Raw data\n",
    "\n",
    "In Azure, this is usually:\n",
    "\n",
    "* Microsoft Azure Data Lake Storage Gen2 (ADLS)\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "> üóÑ A giant cloud folder system.\n",
    "\n",
    "‚ö† No schema enforcement\n",
    "‚ö† No ACID transactions\n",
    "‚ö† No built-in versioning\n",
    "\n",
    "Just files.\n",
    "\n",
    "---\n",
    "\n",
    "# üåä 2Ô∏è‚É£ Delta Lake\n",
    "\n",
    "![Image](https://assets.qlik.com/image/upload/w_1408/q_auto/qlik/glossary/data-lake/seo-hero-delta-lake_n8zbs4.jpg)\n",
    "\n",
    "![Image](https://www.databricks.com/sites/default/files/2025-04/diving-into-delta-lake-unpacking-the-transaction-log-2x.png)\n",
    "\n",
    "![Image](https://av-eks-blogoptimized.s3.amazonaws.com/50982Delta%20lake%202.png)\n",
    "\n",
    "![Image](https://miro.medium.com/0%2A2EMqcFu0OaDK4DfB.png)\n",
    "\n",
    "Delta Lake is a **storage layer** built on top of a data lake.\n",
    "\n",
    "It adds:\n",
    "\n",
    "* ‚úÖ ACID transactions\n",
    "* ‚úÖ Schema enforcement\n",
    "* ‚úÖ Time travel (version history)\n",
    "* ‚úÖ Upserts & deletes (MERGE)\n",
    "* ‚úÖ Transaction log (`_delta_log` folder)\n",
    "\n",
    "It turns a messy data lake into a **reliable data system**.\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "> üß† Smart layer added on top of storage.\n",
    "\n",
    "Still stored as files ‚Äî but now with rules and tracking.\n",
    "\n",
    "---\n",
    "\n",
    "# üßæ 3Ô∏è‚É£ Delta Table\n",
    "\n",
    "A **Delta Table** is simply:\n",
    "\n",
    "> A table stored in Delta Lake format.\n",
    "\n",
    "So:\n",
    "\n",
    "* Data Lake ‚Üí storage\n",
    "* Delta Lake ‚Üí rules + transaction layer\n",
    "* Delta Table ‚Üí actual dataset using Delta format\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "/mnt/datalake/sales/\n",
    "    part-000.parquet\n",
    "    part-001.parquet\n",
    "    _delta_log/\n",
    "```\n",
    "\n",
    "That folder = one Delta table.\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Simple Comparison\n",
    "\n",
    "| Concept     | What It Is                 | Analogy            |\n",
    "| ----------- | -------------------------- | ------------------ |\n",
    "| Data Lake   | Storage system             | Hard drive         |\n",
    "| Delta Lake  | Smart storage framework    | Database engine    |\n",
    "| Delta Table | A table using Delta format | One database table |\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Real-World Flow in Databricks\n",
    "\n",
    "1. Raw files land in ADLS (Data Lake)\n",
    "2. Convert to Delta format ‚Üí becomes Delta Lake managed\n",
    "3. Query as Delta Tables in Databricks\n",
    "\n",
    "---\n",
    "\n",
    "# üí° One-Sentence Summary\n",
    "\n",
    "All Delta tables live inside a data lake,\n",
    "but not all data lake files are Delta tables.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can next explain:\n",
    "\n",
    "* Delta vs traditional SQL database\n",
    "* Or when NOT to use Delta Lake üëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee878e-8f90-48a1-a6b0-7990bd23d7b7",
   "metadata": {},
   "source": [
    "## üöÄ Horizontal Scaling vs Vertical Scaling\n",
    "\n",
    "![Image](https://miro.medium.com/1%2Agee5Zkih2dZ7tYWRgmRbkw.png)\n",
    "\n",
    "![Image](https://media.licdn.com/dms/image/v2/C4E12AQGv6K8fizlDDQ/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1564486772801?e=2147483647\\&t=C9DfS-6gMvWguXhm4QUjGjIHde5cjytqk7dZ-cA88mU\\&v=beta)\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/autoscaling/ec2/userguide/images/elb-tutorial-architecture-diagram.png)\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/autoscaling/ec2/userguide/images/sample-3-tier-architecture-auto-scaling-diagram.png)\n",
    "\n",
    "These are two different ways to handle increasing load in systems like databases, web apps, or Spark clusters.\n",
    "\n",
    "---\n",
    "\n",
    "# üîº Vertical Scaling (Scale Up)\n",
    "\n",
    "**Add more power to one machine.**\n",
    "\n",
    "Example:\n",
    "\n",
    "* Increase CPU from 4 cores ‚Üí 16 cores\n",
    "* Increase RAM from 16GB ‚Üí 128GB\n",
    "* Move to a larger VM size\n",
    "\n",
    "### ‚úÖ Advantages\n",
    "\n",
    "* Simple to implement\n",
    "* No architecture changes\n",
    "* Good for monolithic apps\n",
    "\n",
    "### ‚ùå Disadvantages\n",
    "\n",
    "* Has hardware limits\n",
    "* Can be expensive\n",
    "* Single point of failure\n",
    "* Requires downtime in many cases\n",
    "\n",
    "### üß† Analogy\n",
    "\n",
    "Instead of hiring more workers, you make one worker stronger.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚û° Horizontal Scaling (Scale Out)\n",
    "\n",
    "**Add more machines.**\n",
    "\n",
    "Example:\n",
    "\n",
    "* 1 server ‚Üí 10 servers\n",
    "* 2 Spark workers ‚Üí 20 workers\n",
    "* Load balancer distributes traffic\n",
    "\n",
    "### ‚úÖ Advantages\n",
    "\n",
    "* High availability\n",
    "* No single point of failure\n",
    "* Nearly unlimited scaling\n",
    "* Cloud-native approach\n",
    "\n",
    "### ‚ùå Disadvantages\n",
    "\n",
    "* More complex architecture\n",
    "* Requires distributed system design\n",
    "\n",
    "### üß† Analogy\n",
    "\n",
    "Instead of one super worker, hire more workers.\n",
    "\n",
    "---\n",
    "\n",
    "# üí° In Cloud & Databricks Context\n",
    "\n",
    "In Databricks:\n",
    "\n",
    "* Increasing cluster node size = **Vertical scaling**\n",
    "* Adding more worker nodes = **Horizontal scaling**\n",
    "\n",
    "Most big data systems (Spark, Kafka, distributed DBs) are built for **horizontal scaling**.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Quick Comparison\n",
    "\n",
    "| Feature           | Vertical | Horizontal |\n",
    "| ----------------- | -------- | ---------- |\n",
    "| Add CPU/RAM       | ‚úÖ        | ‚ùå          |\n",
    "| Add More Machines | ‚ùå        | ‚úÖ          |\n",
    "| High Availability | ‚ùå        | ‚úÖ          |\n",
    "| Complexity        | Low      | Higher     |\n",
    "| Cloud-native      | Limited  | Ideal      |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ When to Use What?\n",
    "\n",
    "* Small app? ‚Üí Vertical scaling is fine\n",
    "* Big data, high traffic, enterprise systems? ‚Üí Horizontal scaling\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can explain how this applies specifically to:\n",
    "\n",
    "* Databases\n",
    "* Databricks clusters\n",
    "* Kubernetes\n",
    "* Or system design interviews üëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980daed-e019-4312-a158-2cd00da99579",
   "metadata": {},
   "source": [
    "## ‚ö° Spot Instances (Cloud Cost Optimization)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/10/02/appnext-arch-final-drawing.png)\n",
    "\n",
    "![Image](https://learn.microsoft.com/en-us/azure/architecture/guide/spot/media/spot-virtual-machine-architecture.svg)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/02/24/interruption_notices_arch_diagram.jpg)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2025/11/02/bdb-5236-architecture.png)\n",
    "\n",
    "**Spot instances** are **discounted cloud virtual machines** that use spare capacity from the cloud provider.\n",
    "\n",
    "You can get:\n",
    "\n",
    "* üí∞ 50‚Äì90% cheaper than regular VMs\n",
    "  But‚Ä¶\n",
    "* ‚ö† They can be taken away at any time.\n",
    "\n",
    "---\n",
    "\n",
    "# üè¢ Examples\n",
    "\n",
    "* Amazon EC2 Spot Instances\n",
    "* Microsoft Azure Spot Virtual Machines\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Why Are They Cheap?\n",
    "\n",
    "Cloud providers have unused servers.\n",
    "\n",
    "Instead of leaving them idle:\n",
    "\n",
    "* They sell them at a big discount.\n",
    "* If capacity is needed, your VM is terminated.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚õî The Catch\n",
    "\n",
    "Spot instances:\n",
    "\n",
    "* Can be evicted with short notice (30 seconds‚Äì2 minutes)\n",
    "* No uptime guarantee\n",
    "* Not ideal for critical production workloads\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ When To Use Spot\n",
    "\n",
    "Great for:\n",
    "\n",
    "* Batch jobs\n",
    "* Data processing\n",
    "* Spark workers\n",
    "* CI/CD pipelines\n",
    "* ML training\n",
    "* Dev/test environments\n",
    "\n",
    "Not good for:\n",
    "\n",
    "* Production databases\n",
    "* Stateful systems\n",
    "* Customer-facing APIs\n",
    "\n",
    "---\n",
    "\n",
    "# ‚öô In Databricks Context\n",
    "\n",
    "In Databricks:\n",
    "\n",
    "* Driver node ‚Üí usually on-demand (stable)\n",
    "* Worker nodes ‚Üí can use spot instances\n",
    "\n",
    "If a worker is killed:\n",
    "\n",
    "* Spark redistributes work\n",
    "* Cluster auto-recovers\n",
    "\n",
    "This makes spot perfect for big data workloads.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Quick Comparison\n",
    "\n",
    "| Feature            | On-Demand VM | Spot VM         |\n",
    "| ------------------ | ------------ | --------------- |\n",
    "| Price              | High         | Very Low        |\n",
    "| Guaranteed uptime  | Yes          | No              |\n",
    "| Can be interrupted | No           | Yes             |\n",
    "| Best for           | Production   | Batch workloads |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Simple Analogy\n",
    "\n",
    "Spot instance = Discount airline ticket\n",
    "Cheap, but your flight might get canceled.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can explain:\n",
    "\n",
    "* Spot vs Reserved instances\n",
    "* How eviction works technically\n",
    "* Or how to safely use spot in Databricks üëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36281f-4319-440d-93d3-dc0ba4900317",
   "metadata": {},
   "source": [
    "Short answer: **Technically yes in some systems ‚Äî but almost always a bad idea.**\n",
    "\n",
    "Let‚Äôs break it down clearly.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† What Is a Master (Driver) Node?\n",
    "\n",
    "In distributed systems (like Spark, Hadoop, Kubernetes):\n",
    "\n",
    "* **Master / Driver node** = controls the cluster\n",
    "* Schedules work\n",
    "* Tracks state\n",
    "* Manages workers\n",
    "\n",
    "If it dies ‚Üí the whole job usually fails.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ö† Why Spot Is Risky for Master Node\n",
    "\n",
    "Remember:\n",
    "\n",
    "Spot instances:\n",
    "\n",
    "* Can be terminated anytime\n",
    "* Have no uptime guarantee\n",
    "\n",
    "If your **master node** is spot:\n",
    "\n",
    "* ‚ùå Cluster goes down if evicted\n",
    "* ‚ùå Running jobs fail\n",
    "* ‚ùå State may be lost\n",
    "* ‚ùå Production pipelines break\n",
    "\n",
    "That‚Äôs why it‚Äôs usually avoided.\n",
    "\n",
    "---\n",
    "\n",
    "# üî• In Databricks\n",
    "\n",
    "Best practice:\n",
    "\n",
    "* ‚úÖ Driver node ‚Üí On-demand (stable VM)\n",
    "* ‚úÖ Worker nodes ‚Üí Spot (cheap & replaceable)\n",
    "\n",
    "If a worker dies:\n",
    "\n",
    "* Spark recomputes lost tasks\n",
    "* Cluster recovers automatically\n",
    "\n",
    "If driver dies:\n",
    "\n",
    "* Entire job fails\n",
    "\n",
    "So driver = stable\n",
    "Workers = disposable\n",
    "\n",
    "---\n",
    "\n",
    "# üèó When Could Master Be Spot?\n",
    "\n",
    "Only when:\n",
    "\n",
    "* It‚Äôs a short-lived batch cluster\n",
    "* Job is retry-safe\n",
    "* No long-running service\n",
    "* Cost is more important than reliability\n",
    "\n",
    "Even then, it's risky.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Quick Rule\n",
    "\n",
    "| Node Type       | Spot Safe?    |\n",
    "| --------------- | ------------- |\n",
    "| Worker          | ‚úÖ Yes         |\n",
    "| Master / Driver | üö´ Usually No |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Simple Analogy\n",
    "\n",
    "Workers = temporary contractors\n",
    "Master = project manager\n",
    "\n",
    "You can replace contractors easily.\n",
    "Losing the manager mid-project? Chaos.\n",
    "\n",
    "---\n",
    "\n",
    "If you'd like, I can explain:\n",
    "\n",
    "* How auto-recovery works in Spark\n",
    "* Or how production clusters are designed in enterprise setups üëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3eeefd-aed0-4a5c-b5b6-6bf8a1585e57",
   "metadata": {},
   "source": [
    "In cloud platforms like **Amazon Web Services**, **Microsoft Azure**, and **Google Cloud**, **tags** are key-value labels you attach to resources (VMs, storage, databases, etc.) to organize, track, and manage them.\n",
    "\n",
    "---\n",
    "\n",
    "# üîñ What Is a Tag?\n",
    "\n",
    "A **tag = Key + Value**\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Environment = Production\n",
    "Owner = DataTeam\n",
    "Project = CustomerAnalytics\n",
    "CostCenter = FIN-001\n",
    "```\n",
    "\n",
    "Think of tags like sticky notes attached to your cloud resources.\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Why Tags Are Useful\n",
    "\n",
    "## 1Ô∏è‚É£ Cost Tracking (Very Important üí∞)\n",
    "\n",
    "Imagine your company has 3 teams:\n",
    "\n",
    "* Data Team\n",
    "* Dev Team\n",
    "* ML Team\n",
    "\n",
    "All of them create resources like:\n",
    "\n",
    "* Virtual Machines\n",
    "* Databases\n",
    "* Storage\n",
    "\n",
    "Without tags ‚Üí You get one big cloud bill üòµ\n",
    "With tags ‚Üí You can split the bill by team.\n",
    "\n",
    "Example:\n",
    "\n",
    "| Resource | Monthly Cost | Tag       |\n",
    "| -------- | ------------ | --------- |\n",
    "| VM-01    | $500         | Team=Data |\n",
    "| VM-02    | $300         | Team=Dev  |\n",
    "| DB-01    | $700         | Team=Data |\n",
    "\n",
    "Now you can filter costs by:\n",
    "\n",
    "```\n",
    "Team = Data\n",
    "```\n",
    "\n",
    "And see exactly how much the Data team spends.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Environment Separation (Dev / Test / Prod)\n",
    "\n",
    "Companies usually have:\n",
    "\n",
    "* Dev\n",
    "* Test\n",
    "* Production\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Environment = Dev\n",
    "Environment = Prod\n",
    "```\n",
    "\n",
    "Now:\n",
    "\n",
    "* You can delete all **Dev** resources safely.\n",
    "* You avoid accidentally shutting down Production.\n",
    "\n",
    "Very common real-world use case.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Access Control (Security)\n",
    "\n",
    "You can use tags to control who can manage resources.\n",
    "\n",
    "Example in Azure:\n",
    "\n",
    "```\n",
    "Owner = Harish\n",
    "```\n",
    "\n",
    "Then create a rule:\n",
    "\n",
    "* Only Harish can modify resources with `Owner=Harish`.\n",
    "\n",
    "This is used in:\n",
    "\n",
    "* IAM policies in AWS\n",
    "* Azure RBAC conditions\n",
    "* GCP IAM conditions\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Automation\n",
    "\n",
    "You can automate actions using tags.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "AutoShutdown = Yes\n",
    "```\n",
    "\n",
    "A script runs every night:\n",
    "\n",
    "* Finds resources with `AutoShutdown=Yes`\n",
    "* Stops them at 10 PM\n",
    "\n",
    "This saves money üí∏\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Governance & Compliance\n",
    "\n",
    "For example, your company policy says:\n",
    "\n",
    "Every resource MUST have:\n",
    "\n",
    "* Environment\n",
    "* Owner\n",
    "* CostCenter\n",
    "\n",
    "If someone creates a VM without tags ‚Üí creation is blocked.\n",
    "\n",
    "This helps in:\n",
    "\n",
    "* Large enterprises\n",
    "* Fintech companies\n",
    "* Regulated industries\n",
    "\n",
    "---\n",
    "\n",
    "# üè¢ Real Company Example\n",
    "\n",
    "Let‚Äôs say your company uses **Microsoft Azure** and runs:\n",
    "\n",
    "* 50 VMs\n",
    "* 20 Databases\n",
    "* 10 Storage Accounts\n",
    "\n",
    "You apply this tagging strategy:\n",
    "\n",
    "| Key         | Example Values      |\n",
    "| ----------- | ------------------- |\n",
    "| Environment | Dev / Test / Prod   |\n",
    "| Team        | Data / ML / Backend |\n",
    "| Owner       | Person name         |\n",
    "| Project     | CustomerApp         |\n",
    "| CostCenter  | FIN-001             |\n",
    "\n",
    "Now finance can:\n",
    "\n",
    "* Filter cost by Project\n",
    "* Audit unused resources\n",
    "* Charge back teams\n",
    "\n",
    "Without tags ‚Üí chaos\n",
    "With tags ‚Üí full control\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Simple Analogy\n",
    "\n",
    "Think of tags like:\n",
    "\n",
    "* Labels on folders in a cabinet\n",
    "* Hashtags on Instagram\n",
    "* Categories in Gmail\n",
    "\n",
    "They don‚Äôt change the resource itself ‚Äî\n",
    "They just help you organize and control it.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ö° Interview-Level Summary\n",
    "\n",
    "Tags in cloud are used for:\n",
    "\n",
    "* Cost allocation\n",
    "* Resource organization\n",
    "* Access control\n",
    "* Automation\n",
    "* Governance\n",
    "* Compliance\n",
    "* Billing reports\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also explain:\n",
    "\n",
    "* Tag strategy best practices (enterprise level)\n",
    "* Difference between tags and labels\n",
    "* Real Azure/AWS tagging limits\n",
    "* How Databricks uses tags internally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a9280-fa99-47b0-bbb1-547d7ed7a14a",
   "metadata": {},
   "source": [
    "### **Question: What is policy while creating DBX cluster in Azure Databricks?**\n",
    "\n",
    "---\n",
    "\n",
    "### **Answer:**\n",
    "\n",
    "A **Cluster Policy** in **Azure Databricks** is a **set of rules that control how clusters can be created**.\n",
    "\n",
    "It restricts:\n",
    "\n",
    "* VM size\n",
    "* Number of nodes\n",
    "* Auto-scaling limits\n",
    "* Spot instance usage\n",
    "* Runtime version\n",
    "* And other cluster settings\n",
    "\n",
    "üëâ In simple words:\n",
    "**Policy = Governance rules for cluster creation**\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Why Cluster Policies Are Needed\n",
    "\n",
    "In companies:\n",
    "\n",
    "* Many users create clusters.\n",
    "* Without control ‚Üí people create very large clusters.\n",
    "* This increases cloud cost üí∏\n",
    "* Can also violate security rules.\n",
    "\n",
    "So admins create **cluster policies** to:\n",
    "\n",
    "* Control cost\n",
    "* Enforce standards\n",
    "* Prevent misuse\n",
    "* Maintain governance\n",
    "\n",
    "---\n",
    "\n",
    "# üè¢ Example Scenario\n",
    "\n",
    "Let‚Äôs say your company uses **Microsoft Azure**.\n",
    "\n",
    "Admin creates a policy:\n",
    "\n",
    "```\n",
    "Max Workers = 5\n",
    "VM Size = Standard_DS3_v2 only\n",
    "Auto Termination = 30 minutes\n",
    "Spot Instances = Not Allowed\n",
    "```\n",
    "\n",
    "Now when a developer tries to:\n",
    "\n",
    "* Create 20 workers ‚ùå (blocked)\n",
    "* Choose large VM ‚ùå (not allowed)\n",
    "* Disable auto-termination ‚ùå (not allowed)\n",
    "\n",
    "They must follow the policy.\n",
    "\n",
    "---\n",
    "\n",
    "# üîê Types of Restrictions in Cluster Policy\n",
    "\n",
    "Cluster policies can:\n",
    "\n",
    "### 1Ô∏è‚É£ Fix a value (User cannot change)\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Auto Termination = 30 mins (fixed)\n",
    "```\n",
    "\n",
    "### 2Ô∏è‚É£ Limit a range\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Min Workers = 1\n",
    "Max Workers = 5\n",
    "```\n",
    "\n",
    "### 3Ô∏è‚É£ Hide settings\n",
    "\n",
    "User won‚Äôt even see certain advanced options.\n",
    "\n",
    "---\n",
    "\n",
    "# üí∞ Cost Control Example\n",
    "\n",
    "Without policy:\n",
    "\n",
    "* User creates 10 clusters\n",
    "* Each with 16 workers\n",
    "* No auto-termination\n",
    "\n",
    "Huge Azure bill üòµ\n",
    "\n",
    "With policy:\n",
    "\n",
    "* Max 5 workers\n",
    "* Auto-terminate after 30 mins\n",
    "* Only approved VM types\n",
    "\n",
    "Cost stays controlled.\n",
    "\n",
    "---\n",
    "\n",
    "# üèõ Enterprise-Level Importance\n",
    "\n",
    "Cluster Policies help in:\n",
    "\n",
    "* Data governance\n",
    "* Budget control\n",
    "* Security compliance\n",
    "* Standardization across teams\n",
    "\n",
    "Large companies always use cluster policies.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Simple Analogy\n",
    "\n",
    "Think of Cluster Policy like:\n",
    "\n",
    "* Company laptop purchase rules\n",
    "* Only certain models allowed\n",
    "* Budget limit fixed\n",
    "\n",
    "You can buy ‚Äî\n",
    "But within company rules.\n",
    "\n",
    "---\n",
    "\n",
    "# üìù Interview-Ready Definition\n",
    "\n",
    "> A Cluster Policy in Azure Databricks is a governance mechanism that defines rules and restrictions for cluster configuration to control cost, enforce standards, and maintain security compliance.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* Difference between Cluster Policy and RBAC\n",
    "* How policies are written (JSON format)\n",
    "* What happens if no policy is used in enterprise setups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb351a-4fd6-40b0-91b5-1c072bb8492e",
   "metadata": {},
   "source": [
    "### **What is the purpose of a cluster pool?**\n",
    "\n",
    "The **purpose of a cluster pool** (in Databricks) is to **reduce cluster startup time and lower infrastructure costs** by keeping a set of pre-started virtual machines (VMs) ready to use.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ What is a Cluster Pool?\n",
    "\n",
    "A **cluster pool** is a group of **pre-created, idle virtual machines** that are ready to be attached to a cluster immediately.\n",
    "\n",
    "Instead of:\n",
    "\n",
    "* Creating new VMs every time you start a cluster ‚ùå\n",
    "\n",
    "It:\n",
    "\n",
    "* Reuses already running VMs from the pool ‚úÖ\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Why is it Needed?\n",
    "\n",
    "### 1Ô∏è‚É£ Faster Cluster Startup\n",
    "\n",
    "Without a pool:\n",
    "\n",
    "* Databricks requests new VMs from Azure/AWS\n",
    "* VM provisioning takes **2‚Äì5 minutes**\n",
    "\n",
    "With a pool:\n",
    "\n",
    "* VMs are already running\n",
    "* Cluster starts in **10‚Äì20 seconds**\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Cost Optimization\n",
    "\n",
    "* Idle VMs in the pool can be auto-terminated after a timeout.\n",
    "* Reduces cloud provisioning overhead.\n",
    "* Helps teams avoid repeatedly creating/destroying infrastructure.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Better Resource Management\n",
    "\n",
    "* Admins control:\n",
    "\n",
    "  * VM type\n",
    "  * Min & max pool size\n",
    "  * Auto-termination settings\n",
    "* Ensures consistent compute for teams.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Simple Example\n",
    "\n",
    "Imagine a company using Databricks in Azure:\n",
    "\n",
    "* Data engineers run jobs throughout the day.\n",
    "* They create clusters multiple times.\n",
    "\n",
    "Without Pool:\n",
    "\n",
    "* Every job waits 3‚Äì4 minutes for cluster startup.\n",
    "\n",
    "With Pool:\n",
    "\n",
    "* Company keeps 5 VMs warm in a pool.\n",
    "* Jobs start almost instantly.\n",
    "* Developers are more productive.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Real-Life Analogy\n",
    "\n",
    "Cluster pool = **Parking lot with cars already running üöó**\n",
    "\n",
    "Instead of building a new car every time you want to drive,\n",
    "you just pick one that‚Äôs already ready.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ When Should You Use It?\n",
    "\n",
    "Use cluster pools when:\n",
    "\n",
    "* Many short-lived clusters are created\n",
    "* Teams frequently start/stop clusters\n",
    "* You want faster startup time\n",
    "* You want cost control\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also explain:\n",
    "\n",
    "* Difference between **cluster pool vs job cluster**\n",
    "* How cluster pool works in **Azure Databricks**\n",
    "* When NOT to use cluster pools**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c9134-b948-4555-a0ea-d2074d037d0d",
   "metadata": {},
   "source": [
    "## **What is a Cluster Policy in Databricks (DBX)?**\n",
    "\n",
    "**Cluster policy in Databricks (DBX)** is a set of rules that **controls how clusters can be created and configured** inside a Databricks workspace.\n",
    "\n",
    "It helps organizations:\n",
    "\n",
    "* Control costs üí∞\n",
    "* Enforce security üîê\n",
    "* Standardize configurations ‚öôÔ∏è\n",
    "* Prevent misuse of resources\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Why Do We Need Cluster Policy?\n",
    "\n",
    "Without cluster policies:\n",
    "\n",
    "* Users can create very large clusters\n",
    "* Users can select expensive VM types\n",
    "* Users can enable risky configurations\n",
    "* Costs can go out of control\n",
    "\n",
    "Cluster policies act like **guardrails**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß± How It Works\n",
    "\n",
    "A cluster policy:\n",
    "\n",
    "* Defines allowed VM types\n",
    "* Sets min/max number of workers\n",
    "* Forces certain settings (like auto-termination)\n",
    "* Restricts use of spot instances\n",
    "* Controls runtime versions\n",
    "\n",
    "When a user creates a cluster, they:\n",
    "\n",
    "* Must follow the policy\n",
    "* Cannot change restricted fields\n",
    "\n",
    "---\n",
    "\n",
    "## üè¢ Real-World Example\n",
    "\n",
    "Imagine a company using **Databricks**.\n",
    "\n",
    "### Without Policy:\n",
    "\n",
    "A developer creates:\n",
    "\n",
    "* 20 worker nodes\n",
    "* Large VM size\n",
    "* No auto-termination\n",
    "* Runs all weekend\n",
    "\n",
    "üëâ Huge cloud bill.\n",
    "\n",
    "### With Policy:\n",
    "\n",
    "Company creates a policy:\n",
    "\n",
    "* Max 5 workers\n",
    "* Only Standard_DS3_v2 VM allowed\n",
    "* Auto-terminate after 60 minutes\n",
    "* Spot instances only\n",
    "\n",
    "Now:\n",
    "\n",
    "* No one can exceed limits\n",
    "* Cost is controlled\n",
    "* Environment stays secure\n",
    "\n",
    "---\n",
    "\n",
    "## üõ† Example Cluster Policy (Simple JSON)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"num_workers\": {\n",
    "    \"type\": \"range\",\n",
    "    \"minValue\": 1,\n",
    "    \"maxValue\": 5\n",
    "  },\n",
    "  \"node_type_id\": {\n",
    "    \"type\": \"fixed\",\n",
    "    \"value\": \"Standard_DS3_v2\"\n",
    "  },\n",
    "  \"autotermination_minutes\": {\n",
    "    \"type\": \"fixed\",\n",
    "    \"value\": 60\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This means:\n",
    "\n",
    "* Workers: 1‚Äì5 only\n",
    "* VM size: fixed\n",
    "* Auto-terminate: 60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## üîê Who Creates Cluster Policies?\n",
    "\n",
    "* Workspace Admins\n",
    "* Platform / Cloud team\n",
    "\n",
    "Regular users:\n",
    "\n",
    "* Can only select from available policies\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Types of Restrictions in Policy\n",
    "\n",
    "| Type      | Meaning                      |\n",
    "| --------- | ---------------------------- |\n",
    "| fixed     | User cannot change it        |\n",
    "| range     | User can choose within limit |\n",
    "| allowlist | Only specific values allowed |\n",
    "| forbidden | Setting not allowed          |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† In Simple Words\n",
    "\n",
    "Cluster policy in DBX =\n",
    "üëâ **Rules that control how clusters are created to manage cost, security, and performance.**\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also explain:\n",
    "\n",
    "* Cluster policy vs Azure Policy\n",
    "* How to create cluster policy step-by-step\n",
    "* Interview explanation version üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e35191-b968-415d-afd0-a0e6aa838845",
   "metadata": {},
   "source": [
    "## **What is equivalent to Cluster Policy in AWS?**\n",
    "\n",
    "The **equivalent to Cluster Policy in AWS** is mainly:\n",
    "\n",
    "> **IAM Policies + Service Control Policies (SCP) + Service-specific restrictions**\n",
    "\n",
    "There is no single feature in AWS exactly called ‚ÄúCluster Policy‚Äù like in **Databricks**, but AWS achieves similar control using multiple services.\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ 1Ô∏è‚É£ IAM Policy (Main Equivalent)\n",
    "\n",
    "The closest equivalent is:\n",
    "\n",
    "## üëâ **AWS Identity and Access Management (IAM Policy)**\n",
    "\n",
    "IAM policies control:\n",
    "\n",
    "* Who can create EC2 instances\n",
    "* What instance types they can use\n",
    "* Maximum resources allowed\n",
    "* Permissions on services\n",
    "\n",
    "### Example\n",
    "\n",
    "You can create IAM policy that:\n",
    "\n",
    "* Allows only `t3.medium` EC2 instances\n",
    "* Denies `m5.4xlarge`\n",
    "* Restricts region usage\n",
    "* Blocks certain configurations\n",
    "\n",
    "This is similar to:\n",
    "\n",
    "* Restricting VM type\n",
    "* Restricting size\n",
    "* Controlling cluster configuration\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ 2Ô∏è‚É£ Service Control Policies (For Organization Level)\n",
    "\n",
    "If company uses:\n",
    "\n",
    "## üëâ **AWS Organizations**\n",
    "\n",
    "You can create:\n",
    "\n",
    "* Service Control Policies (SCP)\n",
    "* Restrict entire accounts\n",
    "* Control maximum instance types globally\n",
    "\n",
    "This is like:\n",
    "\n",
    "* Company-wide guardrails\n",
    "* Prevent misuse across teams\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ 3Ô∏è‚É£ Service-Specific Controls (Example: EMR)\n",
    "\n",
    "If using:\n",
    "\n",
    "## üëâ **Amazon EMR**\n",
    "\n",
    "You can:\n",
    "\n",
    "* Restrict instance types\n",
    "* Control cluster size\n",
    "* Limit configurations via IAM + EMR settings\n",
    "\n",
    "That becomes closer to Databricks cluster policy.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Simple Comparison\n",
    "\n",
    "| Databricks                  | AWS Equivalent      |\n",
    "| --------------------------- | ------------------- |\n",
    "| Cluster Policy              | IAM Policy          |\n",
    "| Workspace-level restriction | IAM + SCP           |\n",
    "| Cluster config restriction  | EMR + IAM           |\n",
    "| Force auto-termination      | EC2 lifecycle + IAM |\n",
    "\n",
    "---\n",
    "\n",
    "# üß† In Simple Words\n",
    "\n",
    "Cluster Policy in DBX =\n",
    "üëâ Rules for cluster creation\n",
    "\n",
    "Equivalent in AWS =\n",
    "üëâ IAM Policies + SCP + Service-level restrictions\n",
    "\n",
    "AWS does not have a single ‚Äúcluster policy‚Äù feature.\n",
    "It uses **permission + governance model** instead.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also explain:\n",
    "\n",
    "* Equivalent in Azure\n",
    "* IAM vs SCP difference\n",
    "* Interview-style answer\n",
    "* Real-life architecture example üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310474b-36b1-4a2d-8007-6e7c697e6db6",
   "metadata": {},
   "source": [
    "## What are **Notebooks in Databricks (DBX)?**\n",
    "\n",
    "**Notebooks in Databricks** are interactive web-based documents used to write, run, and document code for data engineering, data science, and analytics inside a Databricks workspace.\n",
    "\n",
    "They combine:\n",
    "\n",
    "* ‚úÖ Code\n",
    "* ‚úÖ Output (tables, charts)\n",
    "* ‚úÖ Markdown (documentation)\n",
    "\n",
    "---\n",
    "\n",
    "## What is a Notebook in DBX?\n",
    "\n",
    "A **Databricks notebook** is a collaborative development environment where you can:\n",
    "\n",
    "* Write code (Python, SQL, Scala, R)\n",
    "* Execute it on a cluster\n",
    "* Visualize results\n",
    "* Share with team members\n",
    "* Build data pipelines or ML models\n",
    "\n",
    "---\n",
    "\n",
    "## Supported Languages in Databricks Notebooks\n",
    "\n",
    "You can use:\n",
    "\n",
    "* **Python**\n",
    "* **SQL**\n",
    "* **Scala**\n",
    "* **R**\n",
    "\n",
    "You can even mix languages using magic commands like:\n",
    "\n",
    "```python\n",
    "%sql\n",
    "SELECT * FROM sales_table\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## How Companies Use Notebooks in Databricks\n",
    "\n",
    "Example in a company:\n",
    "\n",
    "### üîπ Data Engineer\n",
    "\n",
    "* Reads data from S3 / ADLS\n",
    "* Cleans & transforms data\n",
    "* Writes Delta tables\n",
    "\n",
    "### üîπ Data Analyst\n",
    "\n",
    "* Queries Delta tables using SQL\n",
    "* Creates dashboards\n",
    "\n",
    "### üîπ Data Scientist\n",
    "\n",
    "* Trains ML models\n",
    "* Tests algorithms\n",
    "* Saves models to MLflow\n",
    "\n",
    "All this happens inside notebooks.\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Architecture (How it Works)\n",
    "\n",
    "1. Notebook attaches to a **cluster**\n",
    "2. Cluster provides compute\n",
    "3. Code runs on cluster\n",
    "4. Results displayed in notebook\n",
    "\n",
    "If cluster stops ‚Üí notebook cannot run code.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Use Case\n",
    "\n",
    "Suppose a company stores raw sales data in S3.\n",
    "\n",
    "Notebook steps:\n",
    "\n",
    "1. Read raw CSV\n",
    "2. Clean data\n",
    "3. Save as Delta table\n",
    "4. Run SQL queries\n",
    "5. Visualize revenue trends\n",
    "\n",
    "All inside one notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features of Databricks Notebooks\n",
    "\n",
    "* Real-time collaboration (multiple users)\n",
    "* Version control integration (GitHub, Azure DevOps)\n",
    "* Job scheduling\n",
    "* Visualization tools\n",
    "* Markdown documentation\n",
    "* Supports widgets (parameters)\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook vs Traditional IDE\n",
    "\n",
    "| Notebook                | Traditional IDE               |\n",
    "| ----------------------- | ----------------------------- |\n",
    "| Interactive             | File-based                    |\n",
    "| Shows output inline     | Output separate               |\n",
    "| Collaborative           | Mostly single-user            |\n",
    "| Good for data workflows | Good for software development |\n",
    "\n",
    "---\n",
    "\n",
    "## Very Important Concept\n",
    "\n",
    "üëâ A Notebook is **not a database**\n",
    "üëâ It is a **development interface**\n",
    "üëâ It needs a cluster to run code\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can explain:\n",
    "\n",
    "* Notebook vs Jobs\n",
    "* Notebook vs Workspace\n",
    "* How notebooks are stored internally\n",
    "* Production best practices for notebooks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a8ae7-2f31-428e-aa99-5ef8a9e09896",
   "metadata": {},
   "source": [
    "## Do we have notebooks similar to DBX notebooks in AWS?\n",
    "\n",
    "Yes ‚úÖ ‚Äî **AWS provides notebook services similar to Databricks notebooks.**\n",
    "\n",
    "Here are the main ones:\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Amazon SageMaker Studio\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/sagemaker/latest/dg/images/studio/studio-home.png)\n",
    "\n",
    "![Image](https://sagemaker-example-files-prod-us-east-1.s3.amazonaws.com/images/sagemaker-studio-scheduling/overview.png)\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/sagemaker/latest/dg/images/studio-lab-ui.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/12/14/ML-16046-image001.jpg)\n",
    "\n",
    "### What it is:\n",
    "\n",
    "A fully managed ML development environment with Jupyter notebooks.\n",
    "\n",
    "### Similarities to Databricks:\n",
    "\n",
    "* Interactive notebooks\n",
    "* Python support\n",
    "* Attach compute\n",
    "* Visualization\n",
    "* Collaboration\n",
    "\n",
    "### Difference:\n",
    "\n",
    "* Focused more on **Machine Learning**\n",
    "* Not built primarily for big data engineering like Databricks\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Amazon EMR Studio\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2020/12/09/emr-studio-preview-6.jpg)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2023/10/31/BDB-3641_solution_arch-new.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2021/07/16/emr_eks_managed_endpoint_emr_studio_image_1-1.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2020/12/09/emr-studio-preview-1.jpg)\n",
    "\n",
    "### What it is:\n",
    "\n",
    "Notebook environment for running Spark jobs on EMR clusters.\n",
    "\n",
    "### Similarities to Databricks:\n",
    "\n",
    "* Run Spark\n",
    "* Attach to clusters\n",
    "* Data engineering workflows\n",
    "* Big data processing\n",
    "\n",
    "### This is the closest equivalent to Databricks notebooks in AWS.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Amazon Athena Notebook\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2022/10/03/Kepler-2.png)\n",
    "\n",
    "![Image](https://miro.medium.com/0%2AIkJ53fVGMZbTEGGQ.png)\n",
    "\n",
    "![Image](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/05/09/query-athena-sagemaker-8.gif)\n",
    "\n",
    "![Image](https://docs.aws.amazon.com/images/athena/latest/ug/images/notebooks-spark-magics-1.png)\n",
    "\n",
    "### What it is:\n",
    "\n",
    "SQL-based notebook for querying data in S3.\n",
    "\n",
    "### Limitation:\n",
    "\n",
    "* SQL only\n",
    "* No Spark cluster\n",
    "* Not full data engineering environment\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Direct Comparison\n",
    "\n",
    "| Feature        | Databricks Notebook | SageMaker | EMR Studio |\n",
    "| -------------- | ------------------- | --------- | ---------- |\n",
    "| Big Data Spark | ‚úÖ Yes               | ‚ùå Limited | ‚úÖ Yes      |\n",
    "| ML Focus       | ‚úÖ Yes               | ‚úÖ Strong  | ‚ùå Basic    |\n",
    "| Collaboration  | ‚úÖ Strong            | Moderate  | Moderate   |\n",
    "| Delta Lake     | ‚úÖ Native            | ‚ùå No      | ‚ùå No       |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ So What Is AWS Equivalent to DBX Notebook?\n",
    "\n",
    "üëâ For **big data + Spark** ‚Üí **EMR Studio**\n",
    "üëâ For **machine learning** ‚Üí **SageMaker Studio**\n",
    "üëâ For **SQL on S3** ‚Üí **Athena Notebook**\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ Important Concept\n",
    "\n",
    "Databricks = Spark + Delta Lake + Notebook + Cluster management (all integrated)\n",
    "\n",
    "AWS = Separate services combined:\n",
    "\n",
    "* EMR (Spark)\n",
    "* S3 (Storage)\n",
    "* SageMaker (ML)\n",
    "* Athena (SQL)\n",
    "\n",
    "Databricks bundles everything in one platform.\n",
    "\n",
    "---\n",
    "\n",
    "If you want next, I can explain:\n",
    "\n",
    "* Is Databricks better than EMR?\n",
    "* Why companies still use Databricks on AWS?\n",
    "* Cost comparison between EMR and Databricks?\n",
    "* Architecture comparison diagram?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56be34-bfea-4a14-a953-8aba9f0270df",
   "metadata": {},
   "source": [
    "## What are Magic Commands in Notebook?\n",
    "\n",
    "**Magic commands in notebooks** are special commands that start with `%` or `%%` and allow you to perform actions outside normal programming syntax ‚Äî like switching languages, running shell commands, or configuring the environment.\n",
    "\n",
    "They are heavily used in **Databricks notebooks** and Jupyter notebooks.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Magic Commands in Databricks Notebooks\n",
    "\n",
    "In Databricks, magic commands help you:\n",
    "\n",
    "* Switch languages\n",
    "* Run SQL inside Python notebook\n",
    "* Call shell commands\n",
    "* Manage files\n",
    "* Use parameters (widgets)\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Language Magic Commands\n",
    "\n",
    "These allow you to mix languages inside one notebook.\n",
    "\n",
    "### Example:\n",
    "\n",
    "```python\n",
    "%sql\n",
    "SELECT * FROM sales;\n",
    "```\n",
    "\n",
    "Other language magics:\n",
    "\n",
    "* `%python`\n",
    "* `%sql`\n",
    "* `%scala`\n",
    "* `%r`\n",
    "\n",
    "üìå Very useful when:\n",
    "\n",
    "* Data engineer writes Python\n",
    "* Analyst writes SQL\n",
    "* Both work in same notebook\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ %run (Run Another Notebook)\n",
    "\n",
    "```python\n",
    "%run ./common_functions\n",
    "```\n",
    "\n",
    "Used to:\n",
    "\n",
    "* Import another notebook\n",
    "* Reuse code\n",
    "* Share functions across notebooks\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ %fs (File System Commands)\n",
    "\n",
    "Used to interact with DBFS (Databricks File System).\n",
    "\n",
    "```python\n",
    "%fs ls /mnt/data\n",
    "```\n",
    "\n",
    "You can:\n",
    "\n",
    "* List files\n",
    "* Copy files\n",
    "* Move files\n",
    "* Delete files\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ %sh (Shell Commands)\n",
    "\n",
    "Runs Linux commands inside notebook.\n",
    "\n",
    "```python\n",
    "%sh ls -l\n",
    "```\n",
    "\n",
    "Used for:\n",
    "\n",
    "* Installing libraries\n",
    "* Checking system files\n",
    "* Running bash scripts\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Widgets (Parameterization)\n",
    "\n",
    "```python\n",
    "dbutils.widgets.text(\"name\", \"default\")\n",
    "```\n",
    "\n",
    "Used to:\n",
    "\n",
    "* Pass parameters\n",
    "* Make notebook reusable\n",
    "* Use in scheduled jobs\n",
    "\n",
    "Example use case:\n",
    "\n",
    "* Same notebook runs for different dates\n",
    "* Pass date as parameter\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Difference Between % and %%\n",
    "\n",
    "| Symbol | Meaning                |\n",
    "| ------ | ---------------------- |\n",
    "| `%`    | Applies to one line    |\n",
    "| `%%`   | Applies to entire cell |\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "%%sql\n",
    "SELECT * FROM sales;\n",
    "SELECT * FROM customers;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Why Magic Commands Are Important\n",
    "\n",
    "Without magic:\n",
    "\n",
    "* You need separate scripts\n",
    "* Hard to mix SQL + Python\n",
    "* Harder automation\n",
    "\n",
    "With magic:\n",
    "\n",
    "* More interactive\n",
    "* Faster development\n",
    "* Easy collaboration\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ Real Company Example\n",
    "\n",
    "A data engineer:\n",
    "\n",
    "1. Uses `%sql` to explore data\n",
    "2. Uses `%python` to clean data\n",
    "3. Uses `%fs` to check files\n",
    "4. Uses widgets for daily pipeline\n",
    "\n",
    "All inside one notebook.\n",
    "\n",
    "---\n",
    "\n",
    "If you want next, I can explain:\n",
    "\n",
    "* Difference between %run and importing .py file\n",
    "* How magic commands work internally\n",
    "* Production best practices\n",
    "* Common interview questions on magic commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e793ca-8aa8-4e29-9f3b-f9a2bad631c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699202c-ee50-4ade-9aea-3500314e51d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8bb36-43b8-4f5c-8bb8-bf626010636a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs465cs565)",
   "language": "python",
   "name": "cs465cs565"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
